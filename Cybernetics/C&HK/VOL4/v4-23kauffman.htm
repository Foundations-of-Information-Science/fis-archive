<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
   <TITLE>Vol. 4 nr. 2-3 1997</TITLE>
   <META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
   <META NAME="GENERATOR" CONTENT="Mozilla/3.04Gold (Win95; I) [Netscape]">
</HEAD>
<BODY>

<H1 ALIGN=CENTER>CYBERNETICS &amp; HUMAN KNOWING</H1>

<H3 ALIGN=CENTER>A Journal of Second Order Cybernetics &amp; Cyber-Semiotics</H3>

<P>
<HR></P>

<H1 ALIGN=CENTER>Vol. 4 no. 2-3 1997</H1>

<H3>Louis H. Kauffman:<BR>
<I>Virtual Logic - Boolean Algebra, Computer Proofs and Human Proofs</I></H3>

<P><FONT SIZE=+0>In the last installment of this column, I promised to
discuss properties of the duplicating gremlin G - a model for self-reference
and recursion. In the meantime something fascinating has come up. I shall
postpone the gremlin for now.</FONT></P>

<P><FONT SIZE=+0>This column is devoted to a discussion of the relation
between computer proof and human proof. It is a discussion of the relationship
of persons and machines.</FONT></P>

<P><FONT SIZE=+0>Can a computer discover the proof of a theorem in mathematics?
Some would say that this is certainly possible, since the computer has
only to find the right steps. After all, proving a theorem is like solving
a problem in chess, and we are all aware that computers can play quite
a good game of chess. On the other hand, I say that a proof is not a proof
until a person is convinced by it. In fact a mathematical proof is exactly
an argument that is completely convincing to a mathematician! In this sense,
a computer does not, can not produce a proof.</FONT></P>

<P><FONT SIZE=+0>The computer is not convinced of anything. The computer
is set to search for something - a certain series of steps according to
some rules. The computer can indicate the state desired by its programmers.
It does not know the proof. It only finds the steps.</FONT></P>

<P><FONT SIZE=+0>It is a human judgment that propels the result of the
computer’s search into a statement that the computer has &quot;found a
proof&quot;. Indeed the computer has helped us and it has found something
that we can examine. If we judge that to be a proof, then it is a proof
(for us). How do we judge?</FONT></P>

<P><FONT SIZE=+0>This last question is the real question about proof. How
do we know when we have a proof? It is too big a question from many angles.
One view on it will come forth as we look at a specific problem.</FONT></P>

<P><FONT SIZE=+0>Quite recently a computer program at Argonne National
Labs in Argonne, Illinois found a proof for a famous unsolved problem in
Boolean algebra, known as the <I>Robbins Problem</I>. (Incidentally, Robbins
is the name a mathematician Herbert Robbins, who introduced the problem.
We shall not use an apostrophe on the &quot;s&quot; in Robbins when we
say the Robbins problem). The problem can be elegantly stated, and we shall
state it. But first a story:</FONT></P>

<P><FONT SIZE=+0>A computer proof of the Robbins Problem was completed
on October 10, 1996 by a program named &quot;EQP&quot;. The proof was successfully
verified by another program named &quot;Otter&quot;. It was already known
that it would be sufficient for the computer to deduce a certain equational
pattern from the Robbins Axioms. EQP succeeded in locating this form. The
computer output of the final demonstration is not long, but it contains
many formulas that are exceedingly difficult for a human being to read.
For example, one line of the proof reads:</FONT></P>

<P><FONT SIZE=+0>~(~(~(~(~(X)+X) + ~(~(X) + X) + X+X+X+X) +~(~(~(X)+X)+X+X+X)+X)+X)
= ~(~(~(X) + X)+~(~(X)+X)+X+X+X+X).</FONT></P>

<P><FONT SIZE=+0>This run on the Robbins problem was initiated by William
McCune, a PhD mathematician and member of a group of researchers in automated
theorem proving at the Argonne Labs. The head of the group is Larry Wos.
Credit for the initiative goes to Dr. McCune and to the team who set the
computer on the track of the problem.</FONT></P>

<P><FONT SIZE=+0>It might seem that the demonstration of the Robbins Problem
by the program EQP is out of human reach. This is not so! It is possible
to change the representation of the problem in such a way that a human
can check the proof and even appreciate the form of reasoning used by EQP.
In fact, this mode of representation creates an arena in which one can
continue the investigation either by hand, or with the aid of the computer.</FONT></P>

<P><FONT SIZE=+0>EQP’s human guides were asked how they knew the demonstration
was correct. Their very good answer is that, along with checking it by
hand, they set another program (Otter) to checking and rederiving EQP’s
results and that it is confirmed. I was very curious about this and found
their web page [M]. There, reproduced, were the output lists of EQP and
Otter. Could a human being follow the proof? I decided to give it a try.
The first part of this task, entailed a simplification and translation
of the notation used by the computer. It is very difficult for a human
being to keep track of nested parentheses, but not too hard to look at
patterns of nested boxes. Accordingly I translated the steps in the proof
into a nested box notation. I had previously worked on the Robbins problem
using this notation [K].</FONT></P>

<P><FONT SIZE=+0>The translation of EQP’s proof was not trivial. I had
to find derivations of the statements in the EQP proof. These were not
given, just the sequence of propositions leading to the final result. It
<I>is</I> possible to humanly comprehend the EQP proof! If you are interested
in the details see my web page [KW] and the article therein on Robbins
Algebra.</FONT></P>

<P><FONT SIZE=+0>It is quite fascinating to contemplate the present situation.
EQP produced a proof that could have been inaccessible to human beings
but is certainly understandable to us with a little effort in communication.
EQP’s proof is much more than a calculation. The proof depends upon a successful
search among a realm of possibilities and the skillful application of pattern
recognition and the application of axioms. This is very close to the work
of a human mathematician. EQP, being able to handle many possibilities
and great depths of parentheses has an advantage over her human colleagues.
I understood EQP’s proof with an enjoyment that was very much the same
as the enjoyment that I get from a proof produced by a human being. Understanding
a proof is like listening to a piece of music - or like improvising a piece
of music from an incomplete score.</FONT></P>

<P><FONT SIZE=+0>Some dark thoughts arise. In the instance of the Robbins
problem, the computer demonstration is just barely comprehensible to humans.
What will happen next? Should we expect proofs by computers that are forever
beyond human understanding? Can such structures be legitimately considered
to be proofs? What will happen to mathematics if major theorems are &quot;proved&quot;
by machines with proofs that cannot be understood by humans? I will leave
you to contemplate these questions as we enter into the structure of the
Robbins problem.</FONT></P>

<P><FONT SIZE=+0>In order to understand the Robbins problem it is neccessary
to know about <I>Boolean algebra</I>. Boolean algebra was discovered/invented
by George Boole [B] as an <I>algebra for logic</I>. Boole had the happy
idea that one could use the notation of ordinary algebra, but re-interpret
it to express the meanings of symbolic logic while retaining the calculating
power of the algebra. I will describe this idea of Boole in modern notation.</FONT></P>

<P><FONT SIZE=+0>Boolean algebra is the algebra that describes the simple
properties of a single distinction. This represents the simplicity of on/off,
outside/inside, true/false, present/absent. In the case of true and false,
Boolean logic assumes a simplicity that idealizes our experience. I shall
recall Boolean algebra by first recalling its interpretation for the logic
of true and false.</FONT></P>

<P><FONT SIZE=+0>In Boolean algebra </FONT></P>

<CENTER><P><B><FONT SIZE=+0>~A means &quot;not A&quot; while<BR>
A+B denotes &quot;A or B&quot; and<BR>
A*B denotes &quot;A and B&quot;.</FONT></B></P></CENTER>

<P><FONT SIZE=+0>With this interpretation in mind, many rules of logic
become identities in the algebra. For example,</FONT></P>

<CENTER><P><FONT SIZE=+0>~~A = A</FONT></P></CENTER>

<P><FONT SIZE=+0>means &quot;Not not A is equivalent to A&quot;.</FONT></P>

<CENTER><P><FONT SIZE=+0>~(~A*~B) = A+B</FONT></P></CENTER>

<P><FONT SIZE=+0>means that the statements &quot;It is not the case that
neither A nor B&quot; and &quot;Either A or B&quot; are logically equivalent.</FONT></P>

<P><FONT SIZE=+0>Once one has a few identities of this sort, it is possible
by algebraic substitution and rearrangement to obtain many other identities.
For example, from</FONT></P>

<CENTER><P><FONT SIZE=+0>~(~A*~B) = A+B</FONT></P></CENTER>

<P><FONT SIZE=+0>we deduce that</FONT></P>

<CENTER><P><FONT SIZE=+0>~~(~A*~B) = ~(A+B)</FONT></P></CENTER>

<P><FONT SIZE=+0>by applying negation to both sides of the equation. Then,
using the general rule that ~~X = X for any X, we get that</FONT></P>

<CENTER><P><FONT SIZE=+0>~A*~B = ~(A+B).</FONT></P></CENTER>

<P><FONT SIZE=+0>Then we substitute ~A for A and ~B for B, obtaining</FONT></P>

<CENTER><P><FONT SIZE=+0>~~A*~~B = ~(~A+~B).</FONT></P></CENTER>

<P><FONT SIZE=+0>Finally, we use ~~X=X again, and get</FONT></P>

<CENTER><P><FONT SIZE=+0>A * B = ~(~A+~B).</FONT></P></CENTER>

<P><FONT SIZE=+0>This reads out as: The statements &quot;A and B&quot;
and &quot;It is not the case that not A or not B&quot; are logically equivalent.</FONT></P>

<P><FONT SIZE=+0>The last rule is called &quot;DeMorgan’s Law&quot; (after
the logician Augustus DeMorgan 1806-1871). It makes explicit the fact that
we can express &quot;and&quot; in terms of the operations &quot;not&quot;
and &quot;or&quot;. Incidentally, we use here the <I>inclusive or</I> that
means &quot;A or B but not both&quot;. Exclusive or can make some claims
for being the most fundamental logical operation, and we shall return to
it in due time (and later columns).</FONT></P>

<P><FONT SIZE=+0>There are many rules in Boolean algebra. One wants an
axiom system of small size from which all the true equations can be deduced.
There are many such systems of axioms. Here is a standard example:</FONT></P>

<P><B><FONT SIZE=+0>Standard Axioms for a Boolean Algebra</FONT></B></P>

<P><FONT SIZE=+0>0. The Boolean algebra B is a set that is endowed with
a binary operation denoted &quot;+&quot; and a unary operation denoted
&quot;~&quot;. The set is closed under these operations. That is, given
a and b in B, then a+b is in B and &atilde; is in B.</FONT></P>

<P><FONT SIZE=+0>1. The operation + is commutative and associative. That
is a+b = b+a for all a and b in B, and (a+b)+c = a + (b+c) for all a, b,
c in B.</FONT></P>

<P><FONT SIZE=+0>2. There is a special element called &quot;zero&quot;
and denoted by the symbol &quot;0&quot; such that 0+a = a for all a in
B. ~0 is denoted by the symbol &quot;1&quot;.</FONT></P>

<P><FONT SIZE=+0>3. ~~a = a for all a in B.</FONT></P>

<P><FONT SIZE=+0>4. ~(a + ~a) = 0 for all a in B.</FONT></P>

<P><FONT SIZE=+0>5. a + ~(~b + ~c) = ~(~(a+b) + ~(a+c)) for all a, b, c
in B.</FONT></P>

<P><FONT SIZE=+0>From these axioms one can deduce all the other facts that
are true in Boolean algrebra.</FONT></P>

<P><FONT SIZE=+0>Commutativity and associativity are part of the simplification
of ordinary language to the mathematics of this model. We say &quot;scotch
and sode&quot; and we do not say &quot;soda and scotch&quot;. In this sense
ordinary language is not commutative. But in the ideal of pure logic, we
imagine that it is possible to just list a set of independent propositions
and to disregard their order. In this sense, the axioms of commutativity
and associativity are like the assumptions of frictionless surfaces and
ideal gases in physics.</FONT></P>

<P><FONT SIZE=+0>For the purposes of logic, 0 means &quot;false&quot; and
1 means true. Axiom 3 says the familiar law of double negation: &quot;Not
not a is equivalent to a&quot;. Axiom 4 says ~(~a+a)=0. Thus Axiom 4 says
that &quot;It is false that it is not the case that either not a or a&quot;.
In English this translates to the algevraic equivalent ~a + a =1: &quot;It
is thie case that either a or not a&quot;. Thus Axiom 4 is a statement
that says that for every element in the Boolean algebra, either a is true
or ~a is true. Again, we are in the idealization that assumes that there
is no ambiguity, no statements beyond true and false in the system B.</FONT></P>

<P><FONT SIZE=+0>Finally, Axiom 5 is better understood if we use the definition
of &quot;and&quot; (as described above): a*b = ~(~a + ~b). Then Axiom 5
reads </FONT></P>

<CENTER><P><FONT SIZE=+0>a + (b*c) = (a*b) + (a*c):</FONT></P></CENTER>

<P><FONT SIZE=+0>The statement &quot;a and either b or c&quot; is equivalent
to the statement &quot;either it is the case that a and b or it is the
case that a and c&quot;.</FONT></P>

<P><FONT SIZE=+0>We tend to understand these statements of logic, once
they are stated in English, by comparing them with images of familiar situations.
The algebra, however, knows nothing but the rules that have been given
to it. In this way the algebra acquires a life of its own. For example,
<I>it is possible to prove Axiom 3 by using the other axioms.</I> In order
to do this you must take a very formal attitude. The well-known interpretations
of the algebra must not be used. The only rules that one can rely upon
are the axioms themselves and the &quot;usual&quot; rules for substitution
and replacement that apply in all algebraic situations.</FONT></P>

<P><FONT SIZE=+0>The author would like to tell you, dear reader, how to
derive Axiom 3 from the other axioms, but this requires careful guidance
in the art of algebraic proof. We must postpone our introduction to that
black art.</FONT></P>

<P><FONT SIZE=+0>In making a proof we may believe that we have shown all
the steps and all the reasons. There is still work for the reader. He or
she has to be able to see the reason for taking a given step! In this sense
every proof, as a text, is full of holes. The holes are filled in by the
person who reads and comprehends the text.</FONT></P>

<P><FONT SIZE=+0>How far can you simplify the axioms for a Boolean algebra?
Huntington made a terrific discovery in 1933 an axiom system for Boolean
algebra that uses only one axiom beyond commutativity and associativity.</FONT></P>

<P><B><FONT SIZE=+0>Huntington’s Axioms for Boolean Algebra</FONT></B></P>

<P><FONT SIZE=+0>0. The Boolean algebra B is a set that is endowed with
a binary operation denoted &quot;+&quot; and a unary operation denoted
&quot;~&quot;. The set is closed under these operations. That is, given
a and b in B, then a+b is in B and ~a is in B.</FONT></P>

<P><FONT SIZE=+0>1. The operation + is commutative and associative. That
is a+b = b+a for all a and b in B, and (a+b)+c = a+(b+c) for all a, b,
c in B. </FONT></P>

<P><FONT SIZE=+0>2. For all a and b in the set B, a = ~(a+b)+ ~(~a+~b).</FONT></P>

<P><FONT SIZE=+0>This discovery of Huntington means that it is possible
to get the whole structure of Boolean algebra from just one special axiom
(plus commutativity, associativity and the conventions of one binary and
one unary operation). Now things are beginning to get interesting. It is
quite a puzzele to derive everything from Huntington’s special axioms.
For example, the first thing that Huntington proves is that ~(a+~a) = ~(b+~b)
for any a and b in B. After he shows this, he can define 0 by the equation
0=~(a+~a). He then has to work quite hard to show that 0 behaves like zero!</FONT></P>

<P><FONT SIZE=+0>In the 1930’s Herbert Robbins, a Professor of Mathematics
at Rutgers University in New Brunswick, New Jersey, asked the seemingly
innocent question: What if we replace Huntington’s Axiom 2. by the following</FONT></P>

<P><I><FONT SIZE=+0>Robbins Axiom 2. For all a and b in the set B, a =
~(~(a+b) + ~(a+~b)).</FONT></I></P>

<P><FONT SIZE=+0>Does this again yield precisely Boolean algebra?! That
question is the Robbins Problem.</FONT></P>

<P><FONT SIZE=+0>It may seem an easy matter to decide this problem. If
you think that this is so, please give it a try. Everyone who has made
the attempt so far has found great difficulty. The difficulty appears at
first to be notational. The big parenthesis surrounding the whole expression
~(~(a+b) + ~(a+~b)) makes it difficult to work with. Then difficulty becomes
frustration and frustration despair as the problem recedes from view and
the mathematician drowns in a sea of unruly paper. On top of this, the
rewards seem very slim. Boolean algebra is well understood. Why should
we worry about a puzzle like this?</FONT></P>

<P><FONT SIZE=+0>Mathematics throws strange and magic puzzles up to its
practioners. These puzzles sometimes become whole fields of study. It is
hard to predict. It is rare to find a challenge that engages the mind just
so. Eventually such puzzles acquire enough associations so that one can
explain why they are important or interesting.</FONT></P>

<P><FONT SIZE=+0>We have come to the end of this column. In the next installment
we shall consider both the structure and the significance of this puzzle
of Herbert Robbins.</FONT></P>

<P><B><FONT SIZE=+0>References</FONT></B></P>

<P><FONT SIZE=+0>[M] </FONT><FONT SIZE=-1>&lt;http:www.mcs.anl.gov/home/mccune/ar/robbins&gt;.</FONT></P>

<P><FONT SIZE=+0>[K] L.H. Kauffman. Robbins Algebra. Proceedings of the
Twentieth International Symposium on Multiple Valued Logic. 54-60, (1990),
IEE Computer Society Press.</FONT></P>

<P><FONT SIZE=+0>[KW] &lt;http://zariski.math.uic.edu:80/~kauffman/&gt;</FONT></P>

<P><FONT SIZE=+0>[B] George Boole, &quot;The Mathematical Analysis of Logic&quot;,
Cambridge, 1847.</FONT></P>

<P><FONT SIZE=+0>[H] E. V. Huntington, Boolean Algebra. A Correction. <I>Trans.
Amer. Math. Soc. </I>35 (1933), pp. 557-558.</FONT></P>

<P>
<HR></P>

<P><A HREF="../../C&HK/vol4/v4-23ind.htm">Return to the content of this issue</A></P>

<P><A HREF="../../C&HK/cyber.htm">Return to the Cybernetics and Human Knowing Homepage</A></P>

<P>
<HR></P>

<H5>The Web edition of Cybernetics and Human Knowing is edited by <A HREF="mailto:sbr@db.dk">S&oslash;ren
Brier<BR>
</A>Rev. 14.01.1998</H5>

</BODY>
</HTML>
