<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN"> 
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Foundations of Information Science : stdin : RE: SV: [Fis] Re: What is the definition of information ?</title>

<script language="javascript" src="../scripts/sniffer.js"></script>
<script language="javascript1.2" src="../scripts/custom.js"></script>
<script language="javascript1.2" src="../scripts/style.js"></script>

</head>

<body topmargin="8" link="#647286" vlink="#647286" alink="#C7D3DA">
<p><a href="../default.htm"><img src="../images/logo.gif" align="top" border="0" WIDTH="474" HEIGHT="33"></a></p><br>

<table width="800"><td><br>

<u><h3>RE: SV: [Fis] Re: What is the definition of information ?</h3></u>
<div class="head">
<h1>RE: SV: [Fis] Re: What is the definition of information ?</h1>
<!-- received="Thu Sep  1 08:49:51 2005" -->
<!-- isoreceived="20050901064951" -->
<!-- sent="Thu,  1 Sep 2005 07:49:52 +0100" -->
<!-- isosent="20050901064952" -->
<!-- name="Srinandan Dasmahapatra" -->
<!-- email="sd@ecs.soton.ac.uk" -->
<!-- subject="RE: SV: [Fis] Re: What is the definition of information ?" -->
<!-- id="1125557392.4316a49038e63@secure.ecs.soton.ac.uk" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="BAY101-F13B1469C92524B4BF4994CB6A10&#64;phx.gbl" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="2136.html" title="Søren Brier: &quot;SV: SV: [Fis] Re: What is the definition of information ?&quot;">Next message</a> ]
[ <a href="2133.html" title="Julio Stern: &quot;RE: SV: [Fis] Re: What is the definition of information ?&quot;">Previous message</a> ]
[ <a href="2133.html" title="Julio Stern: &quot;RE: SV: [Fis] Re: What is the definition of information ?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
 [ <a href="2152.html" title="Shu-Kun Lin: &quot;[Fis] Re: What is the definition of information?&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Srinandan Dasmahapatra &lt;<a href="mailto:sd&#64;ecs.soton.ac.uk?Subject=RE:%20SV:%20[Fis]%20Re:%20What%20is%20the%20definition%20of%20information%20?">sd@ecs.soton.ac.uk</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Thu 01 Sep 2005 - 08:49:52 CEST</span><br />
</address>
<p>
I agree that both these formulations -- as an update of the distribution on X
<br />
or in the appearance of the effects of further observation, or association, or
<br />
anything at all, in the distance function -- capture the essence of how the
<br />
statistical description of the system is affected.  However, when the
<br />
resultinng entropy or variance or some other measure of a particular
<br />
variable's spread is increased, it is quite clear that when we sample from the
<br />
resultinng distribution, we will be able to have less faith in the mean value.
<br />
&nbsp;This rephrases the amount of information about a variable as being the degree
<br />
of surprise samples from it bring.  
<br />
<p>All this can be viewed in its mathematical essence as you have done, or in
<br />
specific applications where the mathematics can be interpreted.  A really
<br />
crude example would be if you bunch up a lot of particles in one spot. 
<br />
Looking at the bunch allows you to quantify its location in a fairly specific
<br />
way.  If the set is subject to diffusion, then the particles form a cloud with
<br />
the speciifcation of its mean providing a less informative description of the
<br />
location of the collection.  Here the observation is merely the interactions
<br />
of the particles with the medium in which they are suspended.  
<br />
<p>A similar case can be made for the dissipation of any localised signal.  For
<br />
instance, the passage of an action potential (a spike) down the axon of a
<br />
neuron will also have an increasing variance with the passage of time as it
<br />
propagates.  
<br />
<p>In all of these examples, information is closely tied in to the specification
<br />
of all the possible outcomes of measurement, or the description of all the
<br />
possible degrees of freedom.  The details of how the spread of the system's
<br />
actual occupation probabilities is measured and what constitutes information
<br />
is already circumscribed by this initial settting of the bounndaries, in the
<br />
choice of variables, and an understanding of the possible values they can
<br />
take.  The rest is handle churning.   What intrigues me most is the fact that
<br />
there are loads of situations -- and let me conjecture wildly, that these
<br />
distinguish living from non-living systems -- in which the possiblities
<br />
themselves can get reinvented midstream, depending on what is required.  Sure,
<br />
we can reconstitute the analysis by taking the sum total of all the variables
<br />
and their possible values at different stages in time and track these changes
<br />
to have a meta-description of changes in entropy, etc., and that *is* a very
<br />
valuable exercise.  But thhe mere fact that we can actively make these changes
<br />
in possibilities is fascinating for me.  
<br />
<p>-- Sri
<br />
<p>Quoting Julio Stern &lt;jmstern&#64;hotmail.com&gt;:
<br />
<p><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I think I CAN agree with this one:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;information is 'a difference that makes a difference'.
</em><br />
<em class="quotelev1">&gt; (e-mail from: Søren Brier)
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; In fact, using the notation below,
</em><br />
<em class="quotelev1">&gt; the amount of information in observation X,
</em><br />
<em class="quotelev1">&gt; relative to the prior p_0, is the prior-posterior
</em><br />
<em class="quotelev1">&gt; ``distance''  D(p_0, p_n)
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; There are several choices for the ``distance''  D( , )
</em><br />
<em class="quotelev1">&gt; A good one the the relative entropy,
</em><br />
<em class="quotelev1">&gt; (or Kullbach-Leibler Divergence)
</em><br />
<em class="quotelev1">&gt; I(p_n,p_0)= \int_\Theta  \log(p_n/p_0) p_n d\theta
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; OBS1:  I(p_n,p_0)=0  ONLY IF  p_n=p_0
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; OBS2: One common critique to this point of view
</em><br />
<em class="quotelev1">&gt; is that this measure of information in the observation X
</em><br />
<em class="quotelev1">&gt; is RELATIVE to the prior, p_0 .
</em><br />
<em class="quotelev1">&gt; As a good Bayesian however,
</em><br />
<em class="quotelev1">&gt; I think that is exactly as it should be...
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; *****************************************
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I work with Bayesian Statistics, where the main operation is of the form
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt;   p_n(\theta) \propto p_{0}(\theta) L(\theta | X)  ,
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; where:
</em><br />
<em class="quotelev1">&gt; - \theta is the (vector) parameter of the statistical model,
</em><br />
<em class="quotelev1">&gt; - p_0 and p_n  are the prior and posterior distributions
</em><br />
<em class="quotelev1">&gt;   of the parameter \theta, and
</em><br />
<em class="quotelev1">&gt; - L(\theta | X) is the likelihood function of \theta,
</em><br />
<em class="quotelev1">&gt;   given the observed data X=[x_1,x_2,...x_n]
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Now: It is possible that the observation X is such that
</em><br />
<em class="quotelev1">&gt; the uncertainty* of p_n is greater than that of p_0
</em><br />
<em class="quotelev1">&gt; (* entropy, variance, or whatever you want)
</em><br />
<em class="quotelev1">&gt; Still, the information in X is statistically relevant!
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; -- Julio Stern
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; _______________________________________________
</em><br />
<em class="quotelev1">&gt; fis mailing list
</em><br />
<em class="quotelev1">&gt; fis&#64;listas.unizar.es
</em><br />
<em class="quotelev1">&gt; <a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<p><p><p><p>_______________________________________________
<br />
fis mailing list
<br />
fis&#64;listas.unizar.es
<br />
<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
<br />
<span id="received"><dfn>Received on</dfn> Thu Sep  1 08:49:51 2005</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="2136.html" title="Next message in the list">Søren Brier: "SV: SV: [Fis] Re: What is the definition of information ?"</a></li>
<li><dfn>Previous message</dfn>: <a href="2133.html" title="Previous message in the list">Julio Stern: "RE: SV: [Fis] Re: What is the definition of information ?"</a></li>
<li><dfn>In reply to</dfn>: <a href="2133.html" title="Message to which this message replies">Julio Stern: "RE: SV: [Fis] Re: What is the definition of information ?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="2152.html" title="Next message in this discussion thread">Shu-Kun Lin: "[Fis] Re: What is the definition of information?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#2135" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#2135" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#2135" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#2135" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p></td></table>

<br><p>
<SMALL> 
<EM> 
This archive was generated by  <A HREF="../../www.hypermail.org/default.htm">hypermail 2.1.8</A> on Thu 01 Sep 2005 - 08:49:52 CEST
</EM> 
</SMALL> 

<script language="javascript1.2" src="../scripts/menu.js"></script>
</body></html>