<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: [Fis] Is all information also physical entropy?</title>
<meta name="Author" content="Michael Devereux (dbar_x@cybermesa.com)" />
<meta name="Subject" content="[Fis] Is all information also physical entropy?" />
<meta name="Date" content="2004-05-06" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>[Fis] Is all information also physical entropy?</h1>
<!-- received="Thu May  6 21:42:58 2004" -->
<!-- isoreceived="20040506194258" -->
<!-- sent="Thu, 06 May 2004 13:41:05 -0600" -->
<!-- isosent="20040506194105" -->
<!-- name="Michael Devereux" -->
<!-- email="dbar_x@cybermesa.com" -->
<!-- subject="[Fis] Is all information also physical entropy?" -->
<!-- id="409A94D1.80908@cybermesa.com" -->
<!-- charset="windows-1252" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1494.html" title="Stanley N. Salthe: &quot;Re: [Fis] order/disorder/causality&quot;">Next message</a> ]
[ <a href="1492.html" title="Loet Leydesdorff: &quot;RE: [Fis] bioinformation and entropy&quot;">Previous message</a> ]
<!-- unextthread="start" -->
[ <a href="1496.html" title="Loet Leydesdorff: &quot;RE: [Fis] Is all information also physical entropy?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Michael Devereux &lt;<a href="mailto:dbar_x&#64;cybermesa.com?Subject=Re:%20[Fis]%20Is%20all%20information%20also%20physical%20entropy?">dbar_x@cybermesa.com</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Thu 06 May 2004 - 21:41:05 CEST</span><br />
</address>
<p>
Dear Loet and colleagues,
<br />
Thanks, Loet, for the message. I always enjoy learning from what you write.
<br />
Are you familiar with the entropy calculation for a physical system 
<br />
which has degenerate energy levels? Emerys article was my tutorial for 
<br />
understanding how to make that computation properly. He specifies that 
<br />
every energy level, including every degenerate level, is individually 
<br />
summed in our familiar equation, Sum p ln(p).
<br />
Before reading his prescription, I had thought that any levels with the 
<br />
same energy must be treated as just one physical state. So, I would sum 
<br />
the probabilities over each degenerate level to find the probability for 
<br />
that single compound degenerate state, and plug that probability into 
<br />
our familiar entropy equation. But, not so, according to Emery. And it 
<br />
does yield a different value for the entropy, doesnt it? Can you 
<br />
confirm Emerys formulation, Loet? Anyone else? Its something I had 
<br />
never considered before.
<br />
Regarding the question of a distinction between thermodynamic entropy 
<br />
and informational entropy, I think, Loet, you and I are considering the 
<br />
problem at a different level. I believe Im starting to understand your 
<br />
use of the decomposition algorithm, with H(0) the in-between group 
<br />
uncertainty.
<br />
I dont doubt that H = Sum p ln(p) is a mathematical formula that may be 
<br />
useful in many different applications, including as a part of some 
<br />
larger formulation, like the decomposition algorithm. But, my 
<br />
perspective is at the most elementary level for information, the level 
<br />
of an information bit. We know, from computer science, dont we, that 
<br />
any information, no matter how complex, may be represented as a series 
<br />
of bits. That would include whatever information one observes for the 
<br />
segregation of social systems, or the expected information flow in 
<br />
internet communication. I trust, Loet, youll agree with me that any 
<br />
macroscopic information, including internet conversations, etc., can 
<br />
be represented as some sequence of bits.
<br />
I also trust youll agree that every bit of information is a physical 
<br />
configuration of some sort. If I receive even a single bit of 
<br />
information, it was conveyed to me by a structure that is physical. For 
<br />
example, a pencil mark on paper, an electrical voltage in a computers 
<br />
transistor, a light photon striking my eye, or a single bit represented 
<br />
by the occupation level of an electron in one of two levels of an atom. 
<br />
And our brains, too, store information as chemical and electrical 
<br />
signals. This is what Rolf Landauer meant when he said that information 
<br />
is physical.
<br />
The Szilard engine represents a single bit by the location of an atom in 
<br />
either one or the other half of a cylinder. Did you know that it is 
<br />
Szilard, via the engine, who is credited with discovering the 
<br />
information bit. So, it was a physical thing from the beginning. One 
<br />
good source for the history and development of information theory is 
<br />
Grandys resource letter, available on the web at 
<br />
<a href="../../physics.uwyo.edu/~tgrandy/infophys/node1.html">http://physics.uwyo.edu/~tgrandy/infophys/node1.html</a>.
<br />
As we know, Shannon calculated the amount of information conveyed by a 
<br />
series of electrical impulses in a telegraph line and rediscovered the 
<br />
formula H. I emphasize that this is the amount of information carried by 
<br />
a particular physical arrangement. It seems to me, then, that the only 
<br />
remaining question is whether the H which quantifies the amount of 
<br />
information in a physical configuration, describes that same property of 
<br />
a physical system as does its entropy, S. As you say, Loet, heat divided 
<br />
by temperature, without the appropriate conversion factor, K, certainly 
<br />
doesnt have the units of information. (But, both do describe the 
<br />
uncertainty, or improbability, in a physical system.) And I realize that 
<br />
Shannon wasnt willing to call his measure entropy, or negentropy, 
<br />
though Brillouin did it for him.
<br />
The final piece of this argument is described by Grandy in his resource 
<br />
letter. He claims the case is now settled; that the property of some 
<br />
physical system measured by S, is, indeed, the same property calculated 
<br />
by the H formula (with an appropriate conversion factor, k). Grandy says 
<br />
that the ENTROPY of any physical system provides a quantitative measure 
<br />
of the AMOUNT OF INFORMATION needed to remove the uncertainty in the 
<br />
probability distribution for that system. Id emphasize that this is so 
<br />
for any physical system at all, whether a few bits of electrical energy 
<br />
in a computer register, or, say, all the information that can possibly 
<br />
be carried by an internet conversation, or by the exchange of cash.
<br />
Thanks, Loet, for the response. It surely helped me clarify my ideas 
<br />
about the H formula.
<br />
Very best regards,
<br />
Michael
<br />
<p><p><p>_______________________________________________
<br />
fis mailing list
<br />
fis&#64;listas.unizar.es
<br />
<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
<br />
<span id="received"><dfn>Received on</dfn> Thu May  6 21:42:58 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1494.html" title="Next message in the list">Stanley N. Salthe: "Re: [Fis] order/disorder/causality"</a></li>
<li><dfn>Previous message</dfn>: <a href="1492.html" title="Previous message in the list">Loet Leydesdorff: "RE: [Fis] bioinformation and entropy"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1496.html" title="Next message in this discussion thread">Loet Leydesdorff: "RE: [Fis] Is all information also physical entropy?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1496.html" title="Message sent in reply to this message">Loet Leydesdorff: "RE: [Fis] Is all information also physical entropy?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1493" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1493" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1493" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1493" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:46 CET
</em></small></p>
</body>
</html>
