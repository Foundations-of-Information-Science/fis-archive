<?xml version="1.0" encoding="us-ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: [Fis] Szilard's Engine and Information</title>
<meta name="Author" content="Michael Devereux (dbar_x@cybermesa.com)" />
<meta name="Subject" content="[Fis] Szilard's Engine and Information" />
<meta name="Date" content="2004-04-05" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>[Fis] Szilard's Engine and Information</h1>
<!-- received="Mon Apr  5 22:46:39 2004" -->
<!-- isoreceived="20040405204639" -->
<!-- sent="Mon, 05 Apr 2004 14:32:32 -0600" -->
<!-- isosent="20040405203232" -->
<!-- name="Michael Devereux" -->
<!-- email="dbar_x@cybermesa.com" -->
<!-- subject="[Fis] Szilard's Engine and Information" -->
<!-- id="4071C260.6070509@cybermesa.com" -->
<!-- charset="us-ascii" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1401.html" title="Pedro C. Marijuán: &quot;Re: [Fis] FIS / introductory text / 5 April 2004&quot;">Next message</a> ]
[ <a href="1399.html" title="Loet Leydesdorff: &quot;RE: [Fis] FIS / introductory text / 5 April 2004&quot;">Previous message</a> ]
<!-- unextthread="start" -->
[ <a href="1402.html" title="Dr. Shu-Kun Lin: &quot;Re: [Fis] Szilard's Engine and Information&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Michael Devereux &lt;<a href="mailto:dbar_x&#64;cybermesa.com?Subject=Re:%20[Fis]%20Szilard's%20Engine%20and%20Information">dbar_x@cybermesa.com</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Mon 05 Apr 2004 - 22:32:32 CEST</span><br />
</address>
<p>
Dear Colleagues,
<br />
I’ve attached a PDF version of this message for those whose browser 
<br />
doesn’t do a good job of reproducing text formatting.
<br />
I am becoming more and more aware of the interest and help provided by 
<br />
other academic disciplines toward my understanding of information and 
<br />
entropy, and I appreciate Michel’s introduction in that regard. May I 
<br />
suggest a powerful model from physics for understanding the 
<br />
information-entropy relationship, at least as we physicists often use 
<br />
those terms in thermodynamics and measurement? ( I was an experimental 
<br />
particle physicist once, at the Los Alamos meson factory, then, in 
<br />
Switzerland working for the ETH on elementary particle experiments. I’ve 
<br />
taught at various universities in the U.S., and am now semi-retired. 
<br />
But, I’ve retained an abiding interest in quantum measurement, which has 
<br />
led to analysis of the Szilard engine and to calculation of the entropy 
<br />
cost of information processing. I expect I may return to full time work 
<br />
in some field related to quantum measurement or quantum information, if 
<br />
such an opportunity arrives. So, my experience and perspective is 
<br />
largely as a practicing physicist.) I understand that this model won’t 
<br />
address many of those concepts enumerated by Michel.
<br />
By far, the most effective and powerful physics model I know for 
<br />
investigating the relationship between thermodynamic entropy and 
<br />
information is the Szilard engine (Szilard, Z. Physik, 53, 1929, p. 840; 
<br />
Devereux, Found. Phys. Lett. 16, 1, 2003, p. 41, also available on the 
<br />
web from the Entropy server). Szilard discovered a very simple model 
<br />
that serves both as a heat engine and an information engine. It bridges 
<br />
the gap between a macroscopic measuring apparatus and microscopic 
<br />
information bit. Can anyone suggest a better model from physics? I’ve 
<br />
found it extremely useful for understanding the cost, in terms of energy 
<br />
and entropy, of quantum measurement, as well as the thermodynamic 
<br />
entropy needed for information processing. Specifically, the 
<br />
“information” here is the location, from measurement, of a single gas 
<br />
molecule in one or another half of a macroscopic cylinder.
<br />
But, the fatal problem with use of the Szilard engine model had been 
<br />
mistaken analysis of the engine cycle. Szilard suggested that the 
<br />
apparatus for measuring location of the gas molecule within the engine 
<br />
cylinder must produce entropy at measurement, in order to protect the 
<br />
Second Law of Thermodynamics. For nearly seventy-five years now, 
<br />
scientists have elaborated, expanded, and formalized that idea. (Zurek 
<br />
in Frontiers of Nonequillibrium Statistical Physics, 1984, p. 151; 
<br />
Lubkin, Int. J. Theo. Phys. 26, 1987, pp. 523-535; Brillouin, J. App. 
<br />
Phys., 22, 3, 1951, p. 334; etc. )
<br />
But, Szilard’s suggestion is mistaken, and quite obviously so, with a 
<br />
little careful consideration. In his model, after measurement of the 
<br />
location, either R or L, of the molecule in one side or the other of 
<br />
each of N cylinders of this engine, the memory register of the 
<br />
measurement apparatus will indicate, for example, (R, L, R, R, L, 
<br />
R,.....). That information is now fixed; it does not change over time 
<br />
with fluctuations of the thermodynamic system, as the engine’s gas 
<br />
molecule continues to collide with the cylinder. So, the 
<br />
information-dependent entropy of the apparatus is zero. Analogous, for 
<br />
example, to an ideal gas with the position and momentum of each gas 
<br />
molecule fixed at specific values. That entropy is zero. (As physicists 
<br />
calculate such things.)
<br />
Thus, the apparatus entropy could not have increased with measurement, 
<br />
and the Second Law is not protected from Maxwell’s demon by an apparatus 
<br />
entropy increase. Two philosophers of science, Earman and Norton, (Stud. 
<br />
Hist. Phil. Mod. Phys., Vol. 30, No. 1, pp. 1-40, 1999) published a 
<br />
quite extensive review of attempts to defend the Second Law from 
<br />
Maxwell’s demon with information-generated entropy, and found no 
<br />
creditable affirmative arguments. (Zurek, in the article cited above, 
<br />
wrote that the measurement outcome is unknown to some external observer, 
<br />
and so, the apparatus entropy is seen to increase by that observer. But, 
<br />
the demon observer must know the measurement outcome for every cylinder, 
<br />
in order to run the engine, and so he finds zero apparatus entropy. As 
<br />
we all know, no scientific law, including the Second Law, is observer 
<br />
dependent. If the demon observes no increase in entropy, then all 
<br />
external observers must also find no increase. This was one of my 
<br />
arguments against Zurek’s analysis. Earman and Norton offered another. I 
<br />
think Zurek’s idea is similar to von Neumann’s notion that quantum 
<br />
measurements are only completed when they become conscious to a human 
<br />
observer.)
<br />
I calculated the entropy change of the Szilard measurement apparatus 
<br />
(cited above). That entropy actually DECREASES by Nk ln(2) at 
<br />
measurement, indicating an apparatus (thermodynamic) information 
<br />
increase. Recall, however, from Maxwell’s original idea, that the demon 
<br />
operating such an engine not only measures the properties of the gas 
<br />
molecules, he also must move the cylinder partition. The Second Law 
<br />
would not be violated if such partition activation produced sufficient 
<br />
entropy. I believe this effect may be general for the usual type of 
<br />
Maxwell demons: that it is partition movement (door closure, etc.) which 
<br />
generates the entropy prescribed by the Second Law, not the entropy 
<br />
which is associated with the information of measurement. In spite of the 
<br />
innumerable publications claiming otherwise.
<br />
I’m somewhere near the middle of the calculation of the entropy 
<br />
generated by partition movement in Szilard’s engine. I think I can make 
<br />
that calculation quite general, and it appears, then, that I can use 
<br />
that result to determine the fundamental entropy cost of information 
<br />
processing. I mean what I’ve understood Charles Bennett and Rolf 
<br />
Landauer to mean by such things: entropy in terms of, say, the Gibbs 
<br />
formulation, and information processing as the logical manipulation of 
<br />
an information bit (erasure, overwriting, etc.). (The renowned 
<br />
philosopher of science, Karl Popper, thought that the Szilard engine 
<br />
could be operated without measurement, and thus, with no information 
<br />
transfer. If so, the engine might teach nothing about the relationship 
<br />
of entropy to information. But, Zurek displayed the quantum mechanical 
<br />
calculation for closure of the partition. The engine gas is not confined 
<br />
to half the cylinder by partition closure alone, but rather by the 
<br />
quantum measurement which follows closure. So, there must be information 
<br />
transfer to run the engine.) And, recall that the Szilard engine has 
<br />
been used by Charles Bennett and others as the model for information 
<br />
stored in a memory register. And, removal of the engine partition, 
<br />
followed by the measurement which reduces the quantum wave function, 
<br />
erases the information originally stored in the (engine) register 
<br />
(R,L,R,R,L,R,L,....).
<br />
Calculation of the entropy produced by partition closure isn’t quite as 
<br />
simple as I once assumed, though the results now seem to give the value 
<br />
I had anticipated. I do think it’s clear, in general, that prompt 
<br />
movement of a physical object, like the engine partition, will produce 
<br />
thermodynamic entropy. Consider the movement of the cylinder in a heat 
<br />
engine, for example. (No quasi-static processes allowed.)
<br />
The calculation, so far, is incomplete, but it has shown something I 
<br />
find really remarkable. The specific information needed to run the 
<br />
Szilard heat engine is carried by a time signal, not by change in a 
<br />
macroscopic physical configuration of any type. It’s this time signal 
<br />
which causes the decrease in apparatus entropy, since it specifies the 
<br />
captured molecule’s position. No heat is transferred to or from the 
<br />
apparatus at measurement, so it shows no change in Clausius’ entropy, 
<br />
Delta Q / T. I’m unaware of any definition of entropy which explicitly 
<br />
includes a time dependence. Does anyone else know of such?
<br />
I think there is, however, a change in entropy, (and, of thermodynamic 
<br />
information) as determined by the Shannon-von Neumann probability 
<br />
formulation. I suspect that, in determining the probabilities we assign 
<br />
to thermodynamic configurations, we must include those that are 
<br />
time-dependent. And, I’ve found that the entropy cost of partition 
<br />
movement also depends on the time employed for that movement.
<br />
Thank you, Michel, for the introduction and direction for this discussion.
<br />
<p>Cordially,
<br />
<p>Michael Devereux
<br />
<p><p>
_______________________________________________
<br />
fis mailing list
<br />
fis&#64;listas.unizar.es
<br />
<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
<br />
<p><p><div>
<ul>
<li>application/pdf attachment: <a href="att-1400/EandIDiscussion1.pdf">EandIDiscussion1.pdf</a></li>
</ul>
<!-- attachment="EandIDiscussion1.pdf" -->
</div>
<span id="received"><dfn>Received on</dfn> Mon Apr  5 22:46:39 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1401.html" title="Next message in the list">Pedro C. Marijuán: "Re: [Fis] FIS / introductory text / 5 April 2004"</a></li>
<li><dfn>Previous message</dfn>: <a href="1399.html" title="Previous message in the list">Loet Leydesdorff: "RE: [Fis] FIS / introductory text / 5 April 2004"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1402.html" title="Next message in this discussion thread">Dr. Shu-Kun Lin: "Re: [Fis] Szilard's Engine and Information"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1402.html" title="Message sent in reply to this message">Dr. Shu-Kun Lin: "Re: [Fis] Szilard's Engine and Information"</a></li>
<li><dfn>Reply</dfn>: <a href="1403.html" title="Message sent in reply to this message">jakulin@acm.org: "RE: [Fis] Szilard's Engine and Information"</a></li>
<li><dfn>Reply</dfn>: <a href="1404.html" title="Message sent in reply to this message">Igor Rojdestvenski: "Re: [Fis] Entropy and information"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1436.html" title="Message sent in reply to this message">John Collier: "Re: [Fis] Szilard's Engine and Information"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1438.html" title="Message sent in reply to this message">Stanley N. Salthe: "Re: [Fis] Szilard's Engine and Information"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1400" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1400" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1400" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1400" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:46 CET
</em></small></p>
</body>
</html>
