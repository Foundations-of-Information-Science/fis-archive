<?xml version="1.0" encoding="us-ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: RE: [Fis]  Data, observations and distributions / was: Re: </title>
<meta name="Author" content="Loet Leydesdorff (loet@leydesdorff.net)" />
<meta name="Subject" content="RE: [Fis]  Data, observations and distributions / was: Re: Probabilistic Entropy" />
<meta name="Date" content="2004-04-19" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>RE: [Fis]  Data, observations and distributions / was: Re: Probabilistic Entropy</h1>
<!-- received="Mon Apr 19 15:08:11 2004" -->
<!-- isoreceived="20040419130811" -->
<!-- sent="Mon, 19 Apr 2004 14:56:50 +0200" -->
<!-- isosent="20040419125650" -->
<!-- name="Loet Leydesdorff" -->
<!-- email="loet@leydesdorff.net" -->
<!-- subject="RE: [Fis]  Data, observations and distributions / was: Re: Probabilistic Entropy" -->
<!-- id="008301c4260d$c7eb8d70$1302a8c0@loet" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="200404191058.i3JAwFq9372671&#64;ds10.itodys.jussieu.fr" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1440.html" title="Michael Devereux: &quot;[Fis] Is Shannon's Entropy of General Applicability?&quot;">Next message</a> ]
[ <a href="1438.html" title="Stanley N. Salthe: &quot;Re: [Fis] Szilard's Engine and Information&quot;">Previous message</a> ]
[ <a href="1437.html" title="Michel Petitjean: &quot;[Fis]  Data, observations and distributions / was: Re: Probabilistic Entropy&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1441.html" title="Karl Javorszky: &quot;AW: [Fis]  Data, observations and distributions / was: Re: Probabilistic Entropy&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Loet Leydesdorff &lt;<a href="mailto:loet&#64;leydesdorff.net?Subject=RE:%20[Fis]%20%20Data,%20observations%20and%20distributions%20/%20was:%20Re:%20Probabilistic%20Entropy">loet@leydesdorff.net</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Mon 19 Apr 2004 - 14:56:50 CEST</span><br />
</address>
<p>
Dear Michel, 
<br />
&nbsp;
<br />
I appreciate your position, but it seems to me that &quot;observed data&quot; can
<br />
only be considered as &quot;experimental data&quot; if they can be specified with
<br />
reference to &quot;expectations&quot;. Otherwise, the interpretation would be
<br />
naturalistic instead of reflexive, and one would no longer be able to
<br />
discuss the quality of the data. But I don't wish to deny the special
<br />
epistemological status of data as codifiers of the communication. After
<br />
the experiment one cannot deny the value of the measurements any longer.
<br />
&nbsp;
<br />
The basis of experimental data, however, is not given, but constructed
<br />
in scientific reasoning. I am not denying that in the context of
<br />
discovery, one may experience this the other way round. However, upon
<br />
reflection the data never speak for themselves, but appear within a
<br />
context of expectations as validations. 
<br />
&nbsp;
<br />
The issue itself is an old one in the philosophy of science, but it was
<br />
somewhat obscured by positivism and empiricism. Perhaps, it leads us too
<br />
far away from information theory. (We don't have to agree on
<br />
philosophical issues!)
<br />
&nbsp;
<br />
Let me provide a quote from Huygens about the issue:
<br />
&nbsp;
<br />
&quot;Against Cartesius's dogma that the nature or notion of a body should
<br />
consist in extension alone, I have a notion of space that differs from
<br />
the notion of a body: space is what may be occupied by a body.&quot;
<br />
&nbsp;
<br />
Eventually, the data (given in the Revelation) remain unknown from a
<br />
scientific perspective. What we have, are the measurement results which
<br />
gain meaning only from a critical distance (embedded in discourse). We
<br />
can hypothesize (Pierce's) &quot;firstness&quot; or (Leibniz') &quot;vis viva&quot; from
<br />
this perspective. I agree that entertaining this hypothesis can be most
<br />
useful for the scientific understanding. 
<br />
&nbsp;
<br />
Reflexivity about the status of the data, however, is most important
<br />
when we study meaning-processing systems. These systems generate
<br />
probabilistic entropy to a much larger extent then thermodynamic
<br />
entropy. Thus, their &quot;existence&quot; can no longer be based on data. The
<br />
measurements are then knowledge-based. With hindsight, this reflection
<br />
has these epistemological implications for other scientific discourses
<br />
(like physics) as well. I have noted that some physicists write &quot;natural
<br />
laws&quot; nowadays between quotation marks.
<br />
&nbsp;
<br />
With kind regards, 
<br />
&nbsp;
<br />
&nbsp;
<br />
Loet 
<br />
&nbsp;&nbsp;_____  
<br />
<p>Loet Leydesdorff 
<br />
Amsterdam School of Communications Research (ASCoR)
<br />
Kloveniersburgwal 48, 1012 CX Amsterdam
<br />
Tel.: +31-20- 525 6598; fax: +31-20- 525 3681 
<br />
&nbsp;&lt;mailto:loet&#64;leydesdorff.net&gt; loet&#64;leydesdorff.net ;
<br />
&lt;<a href="../../www.leydesdorff.net/default.htm">http://www.leydesdorff.net/</a>&gt; <a href="../../www.leydesdorff.net/default.htm">http://www.leydesdorff.net/</a> 
<br />
<p>&nbsp;
<br />
&nbsp;&lt;<a href="../../www.upublish.com/books/leydesdorff-sci.htm">http://www.upublish.com/books/leydesdorff-sci.htm</a>&gt; The Challenge of
<br />
Scientometrics ;  &lt;<a href="../../www.upublish.com/books/leydesdorff.htm">http://www.upublish.com/books/leydesdorff.htm</a>&gt; The
<br />
Self-Organization of the Knowledge-Based Society
<br />
<p><p><p><p><em class="quotelev1">&gt; -----Original Message-----
</em><br />
<em class="quotelev1">&gt; From: fis-bounces&#64;listas.unizar.es
</em><br />
<em class="quotelev1">&gt; [mailto:fis-bounces&#64;listas.unizar.es] On Behalf Of Michel Petitjean
</em><br />
<em class="quotelev1">&gt; Sent: Monday, April 19, 2004 12:58 PM
</em><br />
<em class="quotelev1">&gt; To: fis&#64;listas.unizar.es
</em><br />
<em class="quotelev1">&gt; Subject: [Fis] Data, observations and distributions / was:
</em><br />
<em class="quotelev1">&gt; Re: Probabilistic Entropy
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; To: &lt;fis&#64;listas.unizar.es&gt;
</em><br />
<em class="quotelev1">&gt; Subj: Data, observations and distributions / was: Re:
</em><br />
<em class="quotelev1">&gt; Probabilistic Entropy
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Dear Loet,
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I see what you mean when you write:
</em><br />
<em class="quotelev2">&gt; &gt; The data are
</em><br />
<em class="quotelev2">&gt; &gt; measurement results which can be considered as probability
</em><br />
<em class="quotelev2">&gt; &gt; distributions. Thus, the expected information content of these
</em><br />
<em class="quotelev2">&gt; &gt; distributions and the meaning which these are given in (highly
</em><br />
<em class="quotelev2">&gt; &gt; codified) discourses provide the basis of science.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; But I do not agree. Is there any probabilist confusing the
</em><br />
<em class="quotelev1">&gt; empirical distribution defined from a sample, and the values
</em><br />
<em class="quotelev1">&gt; themselves ? (are there probabilists among FISers ?). Would
</em><br />
<em class="quotelev1">&gt; you confuse a distribution with its observations, for a
</em><br />
<em class="quotelev1">&gt; continuous distribution (e.g. a gaussian) ? Surely no. Same
</em><br />
<em class="quotelev1">&gt; thing for a Poisson distribution (infinite discrete). The
</em><br />
<em class="quotelev1">&gt; confusion arises in the finite discrete case. In Probability,
</em><br />
<em class="quotelev1">&gt; the distribution associated to a random
</em><br />
<em class="quotelev1">&gt; variable X exists, discarding if observations are made or
</em><br />
<em class="quotelev1">&gt; not. For a finite discrete r.v. taking equiprobable values
</em><br />
<em class="quotelev1">&gt; such that P(X=xi)=1/N, we still have no observations, unless
</em><br />
<em class="quotelev1">&gt; we perform the &quot;experiment&quot;, and even if getting a sample of
</em><br />
<em class="quotelev1">&gt; size N of X, we are not ensured to observe exactly one time
</em><br />
<em class="quotelev1">&gt; each value xi (may be x1 appears twice, may be x2 is not
</em><br />
<em class="quotelev1">&gt; observed,...). The empirical distribution based on data is a
</em><br />
<em class="quotelev1">&gt; special case, in which the N observed values (I assume the
</em><br />
<em class="quotelev1">&gt; usual euclidean case) are input in the definition of a
</em><br />
<em class="quotelev1">&gt; probability law and its distribution, for which each value
</em><br />
<em class="quotelev1">&gt; has probability 1/N. And even here, we cannot say that the N
</em><br />
<em class="quotelev1">&gt; data &quot;are&quot; a sample of the empirical law, even if observing
</em><br />
<em class="quotelev1">&gt; such a sample has a certain probability to occur. The data
</em><br />
<em class="quotelev1">&gt; are measured, then the empirical distribution is built. The
</em><br />
<em class="quotelev1">&gt; distributions exist, in general, outside any experiment (in
</em><br />
<em class="quotelev1">&gt; the probabilistic sense). Once the experiment is done, we
</em><br />
<em class="quotelev1">&gt; have observations (which merit together the name of &quot;sample&quot;
</em><br />
<em class="quotelev1">&gt; under some conditions). Now returning to science, and having,
</em><br />
<em class="quotelev1">&gt; say N data xi (e.g. points in R^d): they are not observations
</em><br />
<em class="quotelev1">&gt; of any probability law: building a r.v. X with a distribution
</em><br />
<em class="quotelev1">&gt; such that P(X=xi)=1/N, is just a step in assigning a
</em><br />
<em class="quotelev1">&gt; mathematical model to the physical phenomenon from which the
</em><br />
<em class="quotelev1">&gt; N data were measured. And most time, the empirical
</em><br />
<em class="quotelev1">&gt; distribution has little interest by itself: the modeller will
</em><br />
<em class="quotelev1">&gt; look if the N data, considered as if they are a sample of
</em><br />
<em class="quotelev1">&gt; some parent population, let him to know something about the
</em><br />
<em class="quotelev1">&gt; parent distribution (may be gaussian, may be anything) and
</em><br />
<em class="quotelev1">&gt; its associated parameters. Information is attached to a
</em><br />
<em class="quotelev1">&gt; distribution, with or without any probabilistic or physical
</em><br />
<em class="quotelev1">&gt; experiment. Measures are just physical data. The relations
</em><br />
<em class="quotelev1">&gt; between data and distributions exist in the spirit of the
</em><br />
<em class="quotelev1">&gt; modeller. I would say that the probabilistic entropy H, when
</em><br />
<em class="quotelev1">&gt; it exists, is just a parameter of a distribution, as the
</em><br />
<em class="quotelev1">&gt; mean, the median or the extreme values.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Michel Petitjean                      Email:
</em><br />
<em class="quotelev1">&gt; petitjean&#64;itodys.jussieu.fr
</em><br />
<em class="quotelev1">&gt; Editor-in-Chief of Entropy                   entropy&#64;mdpi.org
</em><br />
<em class="quotelev1">&gt; ITODYS (CNRS, UMR 7086)                      ptitjean&#64;ccr.jussieu.fr
</em><br />
<em class="quotelev1">&gt; 1 rue Guy de la Brosse                Phone: +33 (0)1 44 27 48 57
</em><br />
<em class="quotelev1">&gt; 75005 Paris, France.                  FAX  : +33 (0)1 44 27 68 14
</em><br />
<em class="quotelev1">&gt; <a href="../../www.mdpi.net/default.htm">http://www.mdpi.net</a>                   <a href="../../www.mdpi.org/default.htm">http://www.mdpi.org</a>
</em><br />
<em class="quotelev1">&gt; <a href="../../petitjeanmichel.free.fr/itoweb.petitjean.html">http://petitjeanmichel.free.fr/itoweb.petitjean.html</a>
</em><br />
<em class="quotelev1">&gt; <a href="../../petitjeanmichel.free.fr/itoweb.petitjean.freeware.html">http://petitjeanmichel.free.fr/itoweb.petitjean.freeware.html</a>
</em><br />
<em class="quotelev1">&gt; _______________________________________________
</em><br />
<em class="quotelev1">&gt; fis mailing list
</em><br />
<em class="quotelev1">&gt; <a href="mailto:fis&#64;listas.unizar.es?Subject=RE:%20[Fis]%20%20Data,%20observations%20and%20distributions%20/%20was:%20Re:%20Probabilistic%20Entropy">fis@listas.unizar.es</a> <a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<span id="received"><dfn>Received on</dfn> Mon Apr 19 15:08:11 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1440.html" title="Next message in the list">Michael Devereux: "[Fis] Is Shannon's Entropy of General Applicability?"</a></li>
<li><dfn>Previous message</dfn>: <a href="1438.html" title="Previous message in the list">Stanley N. Salthe: "Re: [Fis] Szilard's Engine and Information"</a></li>
<li><dfn>In reply to</dfn>: <a href="1437.html" title="Message to which this message replies">Michel Petitjean: "[Fis]  Data, observations and distributions / was: Re: Probabilistic Entropy"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1441.html" title="Next message in this discussion thread">Karl Javorszky: "AW: [Fis]  Data, observations and distributions / was: Re: Probabilistic Entropy"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1439" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1439" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1439" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1439" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:46 CET
</em></small></p>
</body>
</html>
