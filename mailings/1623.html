<?xml version="1.0" encoding="windows-1257"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1257" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: Re: [Fis] probability versus power laws</title>
<meta name="Author" content="Viktoras Didziulis (viktoras.didziulis@sci.fi)" />
<meta name="Subject" content="Re: [Fis] probability versus power laws" />
<meta name="Date" content="2004-07-01" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>Re: [Fis] probability versus power laws</h1>
<!-- received="Thu Jul  1 00:03:59 2004" -->
<!-- isoreceived="20040630220359" -->
<!-- sent="Thu, 1 Jul 2004 00:53:04 -0700 (Pacific Daylight Time)" -->
<!-- isosent="20040701075304" -->
<!-- name="Viktoras Didziulis" -->
<!-- email="viktoras.didziulis@sci.fi" -->
<!-- subject="Re: [Fis] probability versus power laws" -->
<!-- id="40E3C2E0.000001.76877@master" -->
<!-- charset="windows-1257" -->
<!-- inreplyto="l03130300bd08c9bde08a&#64;[128.226.180.45]" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1624.html" title="Loet Leydesdorff: &quot;RE: [Fis] Philosophers describe science&quot;">Next message</a> ]
[ <a href="1622.html" title="Michael Devereux: &quot;[Fis] Philosophers describe science&quot;">Previous message</a> ]
[ <a href="1621.html" title="Stanley N. Salthe: &quot;[Fis] probability versus power laws&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1627.html" title="Stanley N. Salthe: &quot;Re: [Fis] probability versus power laws&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Viktoras Didziulis &lt;<a href="mailto:viktoras.didziulis&#64;sci.fi?Subject=Re:%20[Fis]%20probability%20versus%20power%20laws">viktoras.didziulis@sci.fi</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Thu 01 Jul 2004 - 09:53:04 CEST</span><br />
</address>
<p>
Stan, Guy, ...
<br />

<br />
&nbsp;I agree...  And one more article on combination of Zipf's law and Shannon's
<br />
entropy  as a method to identify functional groups within a system: 
<br />
Montemurro M.A. , Zanette D.H., 2001. Entropic analysis of the role of words
<br />
in literary texts. 
<br />
(<a href="../../xxx.arxiv.org/abs/cond-mat/0109218">http://xxx.arxiv.org/abs/cond-mat/0109218</a>)
<br />

<br />
Let me share my speculations on this point again. 
<br />
I'd think power law distributions introduces a notion of SYSTEMS and their
<br />
structures into a field of statistics. In fact whatever we sample or observe
<br />
is not just a POPULATION of events/objects - those are SYSTEMS (or their
<br />
parts) that are sampled. Thus Zipf's law might be useful defining not simply
<br />
whether samples taken represent a population. It probably could indicate
<br />
whether they represent a system being sampled. So let's say if Zipf's law is
<br />
fulfilled, then we can draw sensible conclusions about the structure of a
<br />
system sampled. Otherwise that could mean a composition of system's
<br />
structure being not represented by samples or 'over-sampling' a system by
<br />
biting a piece of yet another system (neighboring or coexisting) in samples.
<br />
Maybe...
<br />

<br />
This is my second cent for this week.
<br />

<br />
Best regards
<br />
Viktoras
<br />

<br />
&nbsp;
<br />
-------Original Message-------
<br />
&nbsp;
<br />
From: Stanley N. Salthe
<br />
Date: Wednesday, June 30, 2004 12:03:36
<br />
To: fis&#64;listas.unizar.es
<br />
Subject: [Fis] probability versus power laws
<br />
&nbsp;
<br />
Guy, and others --
<br />
&nbsp;
<br />
Guy has a realist take on power laws. In effect, one could say that, in
<br />
any collection of the same kinds of events (say, earthquakes), it will be
<br />
the case that there will be far fewer large, powerful examples, and more
<br />
and more examples as one tallies weaker and weaker ones. In texts, one
<br />
finds some words used very infrequently and more words used more frequently
<br />
(Zipf's Law). This dichotomizing is the material substance of power laws.
<br />
These data can be plotted as magnitude (Xi) or frequency (Pi) by rank (i),
<br />
and will show a long tail into smaller (or rarer) instances. So, looking
<br />
at ensemble data, here we are focusing dichotomously, on the relative
<br />
amounts of large magnitude (or common) versus small magnitude (or rare)
<br />
values. This technique can be useful in comparing the slopes of log Xi by
<br />
log i plots. For example, Zipf found that all kinds of texts he
<br />
investigated in many languages all had the same slope. Only &quot;schizophrenic
<br />
word salad&quot; had a different slope.
<br />
&nbsp;
<br />
How does this relate to frequency distributions?. If we take the same set
<br />
of magnitude data, we could compute the frequencies of the various
<br />
magnitudes (if they aren't already frequencies, as with words in texts),
<br />
and we could plot P ( Xi) by Xi, to get a frequency distribution graph.
<br />
Immediately we see the central tendency pop out as the mode of the curve
<br />
showing as a hump. Instead of privileging the extremes of the data as in
<br />
the power law plot based on an ordination imposed on the data from outside,
<br />
we are focusing on the middle of the data collection, which emerges from
<br />
the data itself. The technique becomes useful in statistics, where the mean
<br />
and variances of a sample can be compared with other samples.
<br />
&nbsp;
<br />
In biology and some other fields the statistical mean is often supposed to
<br />
point at some canonical value for Xi, which gets distorted in individuals
<br />
to different degrees due to historical accidents. Whether that kind of
<br />
interpretation could work for, say, earthquakes, seems doubtful. I know of
<br />
no comparable attempt at canonical interpretation of the slope of log Xi /
<br />
log i power plots. Dichotomizing bigger versus smaller (size or presence),
<br />
there might be a hint in the fact that bigger systems are slower to change,
<br />
while smaller ones change more rapidly, delivering in the event more sizes
<br />
(or kinds) of small things, and fewer big ones. In earthquakes, then,
<br />
small slippages would be more common just because fast dynamics have more
<br />
frequent results (whatever THAT could mean!).
<br />
&nbsp;
<br />
Several workers in the past (most elaborately, Belevitch, 1959, Ann. Soc.
<br />
Sci. Bruxelles 73:310-) have suggested that the power plot can be
<br />
interpreted as the cumulative probability distribution for a lognormal
<br />
probability density function, which he shows using a technique of
<br />
rearranging the data.
<br />
&nbsp;
<br />
In any case, it seems that the two techniques are mutually exclusive ways
<br />
of focusing on a data set -- the ends, or the middle. As such, they are
<br />
techniques for probing the data -- tools for analysis. In and of
<br />
themselves they show little about the world, other than that not all
<br />
instances of a kind of thing are identical; rather they are tools for
<br />
comparing different data sets. A test case for the ontological perspective
<br />
might be, if we are looking at fluctuations at thermodynamic equilibrium,
<br />
we could either identify a canonical ensemble of them, showing them to be
<br />
random, or instead find them (a la Tsallis) to make up a power disribution.
<br />
I seem to be leaning toward the notion that this would depend upon one's
<br />
viewpoint on the data!
<br />
&nbsp;
<br />
STAN
<br />
&nbsp;
<br />
&nbsp;
<br />
_______________________________________________
<br />
fis mailing list
<br />
fis&#64;listas.unizar.es
<br />
<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
<br />
. 
<br />
<p><p>
<p><div>
<img src="att-1623/IMSTP.gif" alt="IMSTP.gif" />
<!-- attachment="IMSTP.gif" -->
</div>
<span id="received"><dfn>Received on</dfn> Thu Jul  1 00:03:59 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1624.html" title="Next message in the list">Loet Leydesdorff: "RE: [Fis] Philosophers describe science"</a></li>
<li><dfn>Previous message</dfn>: <a href="1622.html" title="Previous message in the list">Michael Devereux: "[Fis] Philosophers describe science"</a></li>
<li><dfn>In reply to</dfn>: <a href="1621.html" title="Message to which this message replies">Stanley N. Salthe: "[Fis] probability versus power laws"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1627.html" title="Next message in this discussion thread">Stanley N. Salthe: "Re: [Fis] probability versus power laws"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1627.html" title="Message sent in reply to this message">Stanley N. Salthe: "Re: [Fis] probability versus power laws"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1623" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1623" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1623" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1623" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:47 CET
</em></small></p>
</body>
</html>
