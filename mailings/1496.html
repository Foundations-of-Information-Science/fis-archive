<?xml version="1.0" encoding="us-ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: RE: [Fis] Is all information also physical entropy?</title>
<meta name="Author" content="Loet Leydesdorff (loet@leydesdorff.net)" />
<meta name="Subject" content="RE: [Fis] Is all information also physical entropy?" />
<meta name="Date" content="2004-05-07" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>RE: [Fis] Is all information also physical entropy?</h1>
<!-- received="Fri May  7 10:41:49 2004" -->
<!-- isoreceived="20040507084149" -->
<!-- sent="Fri, 7 May 2004 08:00:22 +0200" -->
<!-- isosent="20040507060022" -->
<!-- name="Loet Leydesdorff" -->
<!-- email="loet@leydesdorff.net" -->
<!-- subject="RE: [Fis] Is all information also physical entropy?" -->
<!-- id="002001c433f8$9596cad0$1302a8c0@loet" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="409A94D1.80908&#64;cybermesa.com" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1497.html" title="Stanley N. Salthe: &quot;RE: [Fis] Is all information also physical entropy?&quot;">Next message</a> ]
[ <a href="1495.html" title="by way of  : &quot;[Fis] Re: quantum entropy&quot;">Previous message</a> ]
[ <a href="1493.html" title="Michael Devereux: &quot;[Fis] Is all information also physical entropy?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1497.html" title="Stanley N. Salthe: &quot;RE: [Fis] Is all information also physical entropy?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Loet Leydesdorff &lt;<a href="mailto:loet&#64;leydesdorff.net?Subject=RE:%20[Fis]%20Is%20all%20information%20also%20physical%20entropy?">loet@leydesdorff.net</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri 07 May 2004 - 08:00:22 CEST</span><br />
</address>
<p>
Dear Michael, 
<br />
&nbsp;
<br />
It seems that we still disagree. I agree that everything can eventually
<br />
be described with physics, but I don't agree with the reductionism
<br />
implied in your vision. For example, if we consider the economy as a
<br />
stream of coins and banknotes, we don't understand the value of these
<br />
coins as different. One can write the values as another probability
<br />
distribution or as a second dimension of the same probability
<br />
distribution, etc., but the system of reference for the values is
<br />
different from the system of reference for the coins and banknotes. The
<br />
systems of reference determine the appropriate level of theorizing. For
<br />
example, in this case we need economic theorizing for understanding the
<br />
(non-linear) dynamics of the system under study. If one focuses on the
<br />
exchange processes in a monetary system, one does not have to worry
<br />
about the physics underlying the system, but can use the H for studying
<br />
the communication. 
<br />
&nbsp;
<br />
Thus, the H provides us with a mathematical apparatus (a mathematical
<br />
theory of communication) that can be recombined with special theories of
<br />
communication (for example, systems that circulate money). If one takes
<br />
the system of circulation of banknotes and coins as the system of
<br />
reference--like a national bank has to do--one worries about the physics
<br />
of the system. But if one assumes that the circulation is an economic
<br />
system, a different research agenda can be formulated. Thus, it is
<br />
useful to abstract from the physics and with hindsight the physical
<br />
dimension of higher-order systems can be considered as one dimension
<br />
among other. 
<br />
&nbsp;
<br />
I hope that this is helpful for clearing the misunderstanding. 
<br />
&nbsp;
<br />
With kind regards, 
<br />
&nbsp;
<br />
&nbsp;
<br />
Loet
<br />
&nbsp;
<br />
&nbsp;
<br />
ps. 
<br />
Let me note for the good order that different from Emery, the correct
<br />
equation is: 
<br />
&nbsp;
<br />
S = k N H
<br />
&nbsp;
<br />
In addition to being indepent of the physical interpretation (k), H is
<br />
also independent of the number of units (N), while S is dependent of the
<br />
number of particles. H is only a statistics of the dividedness. (In a
<br />
closed system, it is then the case that Delta S = k Delta H.)
<br />
<p><p><p><p><em class="quotelev1">&gt; -----Original Message-----
</em><br />
<em class="quotelev1">&gt; From: fis-bounces&#64;listas.unizar.es
</em><br />
<em class="quotelev1">&gt; [mailto:fis-bounces&#64;listas.unizar.es] On Behalf Of Michael Devereux
</em><br />
<em class="quotelev1">&gt; Sent: Thursday, May 06, 2004 9:41 PM
</em><br />
<em class="quotelev1">&gt; To: FIS Mailing List
</em><br />
<em class="quotelev1">&gt; Subject: [Fis] Is all information also physical entropy?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Dear Loet and colleagues,
</em><br />
<em class="quotelev1">&gt; Thanks, Loet, for the message. I always enjoy learning from
</em><br />
<em class="quotelev1">&gt; what you write. Are you familiar with the entropy calculation
</em><br />
<em class="quotelev1">&gt; for a physical system
</em><br />
<em class="quotelev1">&gt; which has degenerate energy levels? Emerys article was my
</em><br />
<em class="quotelev1">&gt; tutorial for
</em><br />
<em class="quotelev1">&gt; understanding how to make that computation properly. He
</em><br />
<em class="quotelev1">&gt; specifies that
</em><br />
<em class="quotelev1">&gt; every energy level, including every degenerate level, is individually
</em><br />
<em class="quotelev1">&gt; summed in our familiar equation, Sum p ln(p).
</em><br />
<em class="quotelev1">&gt; Before reading his prescription, I had thought that any
</em><br />
<em class="quotelev1">&gt; levels with the
</em><br />
<em class="quotelev1">&gt; same energy must be treated as just one physical state. So, I
</em><br />
<em class="quotelev1">&gt; would sum
</em><br />
<em class="quotelev1">&gt; the probabilities over each degenerate level to find the
</em><br />
<em class="quotelev1">&gt; probability for
</em><br />
<em class="quotelev1">&gt; that single compound degenerate state, and plug that
</em><br />
<em class="quotelev1">&gt; probability into
</em><br />
<em class="quotelev1">&gt; our familiar entropy equation. But, not so, according to
</em><br />
<em class="quotelev1">&gt; Emery. And it
</em><br />
<em class="quotelev1">&gt; does yield a different value for the entropy, doesnt it? Can you
</em><br />
<em class="quotelev1">&gt; confirm Emerys formulation, Loet? Anyone else? Its something I had
</em><br />
<em class="quotelev1">&gt; never considered before.
</em><br />
<em class="quotelev1">&gt; Regarding the question of a distinction between thermodynamic entropy
</em><br />
<em class="quotelev1">&gt; and informational entropy, I think, Loet, you and I are
</em><br />
<em class="quotelev1">&gt; considering the
</em><br />
<em class="quotelev1">&gt; problem at a different level. I believe Im starting to
</em><br />
<em class="quotelev1">&gt; understand your
</em><br />
<em class="quotelev1">&gt; use of the decomposition algorithm, with H(0) the in-between group
</em><br />
<em class="quotelev1">&gt; uncertainty.
</em><br />
<em class="quotelev1">&gt; I dont doubt that H = Sum p ln(p) is a mathematical formula
</em><br />
<em class="quotelev1">&gt; that may be
</em><br />
<em class="quotelev1">&gt; useful in many different applications, including as a part of some
</em><br />
<em class="quotelev1">&gt; larger formulation, like the decomposition algorithm. But, my
</em><br />
<em class="quotelev1">&gt; perspective is at the most elementary level for information,
</em><br />
<em class="quotelev1">&gt; the level
</em><br />
<em class="quotelev1">&gt; of an information bit. We know, from computer science, dont we, that
</em><br />
<em class="quotelev1">&gt; any information, no matter how complex, may be represented as
</em><br />
<em class="quotelev1">&gt; a series
</em><br />
<em class="quotelev1">&gt; of bits. That would include whatever information one observes for the
</em><br />
<em class="quotelev1">&gt; segregation of social systems, or the expected information flow in
</em><br />
<em class="quotelev1">&gt; internet communication. I trust, Loet, youll agree with me that any
</em><br />
<em class="quotelev1">&gt; macroscopic information, including internet conversations,
</em><br />
<em class="quotelev1">&gt; etc., can
</em><br />
<em class="quotelev1">&gt; be represented as some sequence of bits.
</em><br />
<em class="quotelev1">&gt; I also trust youll agree that every bit of information is a physical
</em><br />
<em class="quotelev1">&gt; configuration of some sort. If I receive even a single bit of
</em><br />
<em class="quotelev1">&gt; information, it was conveyed to me by a structure that is
</em><br />
<em class="quotelev1">&gt; physical. For
</em><br />
<em class="quotelev1">&gt; example, a pencil mark on paper, an electrical voltage in a
</em><br />
<em class="quotelev1">&gt; computers
</em><br />
<em class="quotelev1">&gt; transistor, a light photon striking my eye, or a single bit
</em><br />
<em class="quotelev1">&gt; represented
</em><br />
<em class="quotelev1">&gt; by the occupation level of an electron in one of two levels
</em><br />
<em class="quotelev1">&gt; of an atom.
</em><br />
<em class="quotelev1">&gt; And our brains, too, store information as chemical and electrical
</em><br />
<em class="quotelev1">&gt; signals. This is what Rolf Landauer meant when he said that
</em><br />
<em class="quotelev1">&gt; information
</em><br />
<em class="quotelev1">&gt; is physical.
</em><br />
<em class="quotelev1">&gt; The Szilard engine represents a single bit by the location of
</em><br />
<em class="quotelev1">&gt; an atom in
</em><br />
<em class="quotelev1">&gt; either one or the other half of a cylinder. Did you know that it is
</em><br />
<em class="quotelev1">&gt; Szilard, via the engine, who is credited with discovering the
</em><br />
<em class="quotelev1">&gt; information bit. So, it was a physical thing from the beginning. One
</em><br />
<em class="quotelev1">&gt; good source for the history and development of information theory is
</em><br />
<em class="quotelev1">&gt; Grandys resource letter, available on the web at
</em><br />
<em class="quotelev1">&gt; <a href="../../physics.uwyo.edu/~tgrandy/infophys/node1.html">http://physics.uwyo.edu/~tgrandy/infophys/node1.html</a>.
</em><br />
<em class="quotelev1">&gt; As we know, Shannon calculated the amount of information
</em><br />
<em class="quotelev1">&gt; conveyed by a
</em><br />
<em class="quotelev1">&gt; series of electrical impulses in a telegraph line and
</em><br />
<em class="quotelev1">&gt; rediscovered the
</em><br />
<em class="quotelev1">&gt; formula H. I emphasize that this is the amount of information
</em><br />
<em class="quotelev1">&gt; carried by
</em><br />
<em class="quotelev1">&gt; a particular physical arrangement. It seems to me, then, that
</em><br />
<em class="quotelev1">&gt; the only
</em><br />
<em class="quotelev1">&gt; remaining question is whether the H which quantifies the amount of
</em><br />
<em class="quotelev1">&gt; information in a physical configuration, describes that same
</em><br />
<em class="quotelev1">&gt; property of
</em><br />
<em class="quotelev1">&gt; a physical system as does its entropy, S. As you say, Loet,
</em><br />
<em class="quotelev1">&gt; heat divided
</em><br />
<em class="quotelev1">&gt; by temperature, without the appropriate conversion factor, K,
</em><br />
<em class="quotelev1">&gt; certainly
</em><br />
<em class="quotelev1">&gt; doesnt have the units of information. (But, both do describe the
</em><br />
<em class="quotelev1">&gt; uncertainty, or improbability, in a physical system.) And I
</em><br />
<em class="quotelev1">&gt; realize that
</em><br />
<em class="quotelev1">&gt; Shannon wasnt willing to call his measure entropy, or negentropy,
</em><br />
<em class="quotelev1">&gt; though Brillouin did it for him.
</em><br />
<em class="quotelev1">&gt; The final piece of this argument is described by Grandy in
</em><br />
<em class="quotelev1">&gt; his resource
</em><br />
<em class="quotelev1">&gt; letter. He claims the case is now settled; that the property of some
</em><br />
<em class="quotelev1">&gt; physical system measured by S, is, indeed, the same property
</em><br />
<em class="quotelev1">&gt; calculated
</em><br />
<em class="quotelev1">&gt; by the H formula (with an appropriate conversion factor, k).
</em><br />
<em class="quotelev1">&gt; Grandy says
</em><br />
<em class="quotelev1">&gt; that the ENTROPY of any physical system provides a
</em><br />
<em class="quotelev1">&gt; quantitative measure
</em><br />
<em class="quotelev1">&gt; of the AMOUNT OF INFORMATION needed to remove the uncertainty in the
</em><br />
<em class="quotelev1">&gt; probability distribution for that system. Id emphasize that
</em><br />
<em class="quotelev1">&gt; this is so
</em><br />
<em class="quotelev1">&gt; for any physical system at all, whether a few bits of
</em><br />
<em class="quotelev1">&gt; electrical energy
</em><br />
<em class="quotelev1">&gt; in a computer register, or, say, all the information that can
</em><br />
<em class="quotelev1">&gt; possibly
</em><br />
<em class="quotelev1">&gt; be carried by an internet conversation, or by the exchange of
</em><br />
<em class="quotelev1">&gt; cash. Thanks, Loet, for the response. It surely helped me
</em><br />
<em class="quotelev1">&gt; clarify my ideas
</em><br />
<em class="quotelev1">&gt; about the H formula.
</em><br />
<em class="quotelev1">&gt; Very best regards,
</em><br />
<em class="quotelev1">&gt; Michael
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; _______________________________________________
</em><br />
<em class="quotelev1">&gt; fis mailing list
</em><br />
<em class="quotelev1">&gt; <a href="mailto:fis&#64;listas.unizar.es?Subject=RE:%20[Fis]%20Is%20all%20information%20also%20physical%20entropy?">fis@listas.unizar.es</a> <a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<span id="received"><dfn>Received on</dfn> Fri May  7 10:41:49 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1497.html" title="Next message in the list">Stanley N. Salthe: "RE: [Fis] Is all information also physical entropy?"</a></li>
<li><dfn>Previous message</dfn>: <a href="1495.html" title="Previous message in the list">by way of  : "[Fis] Re: quantum entropy"</a></li>
<li><dfn>In reply to</dfn>: <a href="1493.html" title="Message to which this message replies">Michael Devereux: "[Fis] Is all information also physical entropy?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1497.html" title="Next message in this discussion thread">Stanley N. Salthe: "RE: [Fis] Is all information also physical entropy?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1497.html" title="Message sent in reply to this message">Stanley N. Salthe: "RE: [Fis] Is all information also physical entropy?"</a></li>
<li><dfn>Reply</dfn>: <a href="1498.html" title="Message sent in reply to this message">Lauri Gröhn: "RE: [Fis] Is all information also physical entropy?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1496" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1496" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1496" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1496" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:46 CET
</em></small></p>
</body>
</html>
