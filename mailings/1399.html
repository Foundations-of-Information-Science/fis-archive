<?xml version="1.0" encoding="us-ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: RE: [Fis] FIS / introductory text / 5 April 2004</title>
<meta name="Author" content="Loet Leydesdorff (loet@leydesdorff.net)" />
<meta name="Subject" content="RE: [Fis] FIS / introductory text / 5 April 2004" />
<meta name="Date" content="2004-04-05" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>RE: [Fis] FIS / introductory text / 5 April 2004</h1>
<!-- received="Mon Apr  5 20:40:48 2004" -->
<!-- isoreceived="20040405184048" -->
<!-- sent="Mon, 5 Apr 2004 20:29:20 +0200" -->
<!-- isosent="20040405182920" -->
<!-- name="Loet Leydesdorff" -->
<!-- email="loet@leydesdorff.net" -->
<!-- subject="RE: [Fis] FIS / introductory text / 5 April 2004" -->
<!-- id="005701c41b3b$ea285a30$1302a8c0@loet" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="40718EF1.6060703&#64;mdpi.org" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1400.html" title="Michael Devereux: &quot;[Fis] Szilard's Engine and Information&quot;">Next message</a> ]
[ <a href="1398.html" title="Dr. Shu-Kun Lin: &quot;Re: [Fis] FIS / introductory text / 5 April 2004&quot;">Previous message</a> ]
[ <a href="1398.html" title="Dr. Shu-Kun Lin: &quot;Re: [Fis] FIS / introductory text / 5 April 2004&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1406.html" title="Stanley N. Salthe: &quot;Re: [Fis] FIS / introductory text / 5 April 2004&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Loet Leydesdorff &lt;<a href="mailto:loet&#64;leydesdorff.net?Subject=RE:%20[Fis]%20FIS%20/%20introductory%20text%20/%205%20April%202004">loet@leydesdorff.net</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Mon 05 Apr 2004 - 20:29:20 CEST</span><br />
</address>
<p>
Dear Shu-Kun, 
<br />
<p><em class="quotelev1">&gt; &quot;Higher distinction (distinguishability) - higher 
</em><br />
<em class="quotelev1">&gt; information&quot; conforms with standard information theory: when 
</em><br />
<em class="quotelev1">&gt; we do sampling, if we suddenly find a new species (to say a 
</em><br />
<em class="quotelev1">&gt; new animal or plant species when we are considering 
</em><br />
<em class="quotelev1">&gt; bioinformation or biological diversity assessment, or a new 
</em><br />
<em class="quotelev1">&gt; molecule, to say suddenly a new molecule like C60 is 
</em><br />
<em class="quotelev1">&gt; discovered, in chemoinformation, as Michel mentioned), then 
</em><br />
<em class="quotelev1">&gt; this newly found individual has a lot of information, as a 
</em><br />
<em class="quotelev1">&gt; consequence that this one is simply different from others (it 
</em><br />
<em class="quotelev1">&gt; is unusual). If this is 1 
</em><br />
<em class="quotelev1">&gt; out of
</em><br />
<em class="quotelev1">&gt; 1000000, the probability of this new species is 1 ppm. The 
</em><br />
<em class="quotelev1">&gt; information is I (per species, for this species)=-log 
</em><br />
<em class="quotelev1">&gt; (0.000001)=log 100000. A lot 
</em><br />
<em class="quotelev1">&gt; of information.
</em><br />
<p>How much information is a lot of information? 
<br />
Do you wish to express information in parts pro million as units.
<br />
The advantage of Shannon's information concept is that information can
<br />
be expressed in terms of bits of information (or nits if you wish), but
<br />
the definition is clear. Alternatively, you may be interested in the
<br />
redundancy.
<br />
<p>However, I don't really care about a plus or minus sign. I think that is
<br />
a philosophical discussion about whether a glass in half empty or half
<br />
full.
<br />
<p><em class="quotelev1">&gt; Similarly, if we find a piece of message is about something 
</em><br />
<em class="quotelev1">&gt; happened somewhere very very unusual (very distinguishable 
</em><br />
<em class="quotelev1">&gt; from other things happening everywhere, everyday), then this 
</em><br />
<em class="quotelev1">&gt; is &quot;news&quot; to be reported in the TV and newspapers, because it 
</em><br />
<em class="quotelev1">&gt; is very different. Therefore, 
</em><br />
<em class="quotelev1">&gt; difference
</em><br />
<em class="quotelev1">&gt; is related to information. Sameness is related to entropy.
</em><br />
<p>No, this is confused. When something is unexpected, then the a priori
<br />
information is (almost) zero and therefore the occurrence of the event
<br />
is very informative using Shannon's formulas. The information
<br />
communicated can be defined as: 
<br />
<p>I = Sigma q log (q/p)
<br />
<p>Sigma q represents the a posteriori probability distribution and Sigma p
<br />
the a priori one. Thus, if one of the p's becomes zero, the expectation
<br />
is that it will not occur. If it occurs, it is complete surprise. This
<br />
is precisely the reason why the emergence of a new dimension creates
<br />
infinite information from an a priori perspective. The maximum entropy
<br />
of the system is then changed. (The maximum entropy is equal to log(n)
<br />
with n as the number of categories.)
<br />
<p>Thus, one should distinguish between the expected information value of a
<br />
distribution H (= -Sigma p log p) and the information communicated when
<br />
an event occurs, I (= Sigma q log(q/p)). The latter can be considered as
<br />
dynamic, while the former is instantaneous or static.
<br />
<p>Note that one can evaluate emergence from an a posteriori perspective
<br />
because then the position of q and p are reversed. Thus, one can
<br />
backtrack from the present when a new development began, but one cannot
<br />
predict from the past when a new development emerged (using information
<br />
theory). We use this in technology studies to distinguish between
<br />
diffusion--with the time axis--and codification--to be evaluated from
<br />
the perspective of hindsight. See: Koen Frenken &amp; Loet Leydesdorff,
<br />
Scaling Trajectories in Civil Aircraft (1913-1997), Research Policy
<br />
29(3) (2000) 331-348; at
<br />
<a href="../../www.leydesdorff.net/aircraft/preprint.pdf">http://www.leydesdorff.net/aircraft/preprint.pdf</a> .
<br />
<p>It seems to me that we should not depart from this mathematical
<br />
framework because the discussion otherwise becomes easily confused.
<br />
Particularly because some of the main concepts (e.g., the expected
<br />
information content of a distribution) are counter-intuitive.
<br />
<p><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Loet, what do you think?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Best regards,
</em><br />
<em class="quotelev1">&gt; Shu-Kun
</em><br />
<em class="quotelev1">&gt; 
</em><br />
I hope that this is helpful. (I have now used my two pennies for this
<br />
discussion and I'll be silent for one week, Pedro! :-))
<br />
<p>With kind regards, 
<br />
<p><p>Loet
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I is based on the Shannon's definition of I
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Information I per
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Loet Leydesdorff wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;Dear Shu-Kun,
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;I was just answering Michel's question for a suggestion about the 
</em><br />
<em class="quotelev2">&gt; &gt;relation with reference to Ebeling's book. The formula in the 
</em><br />
<em class="quotelev2">&gt; &gt;Szilard-Brillouin relation is:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;Delta S &gt;= k(B) Delta H
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;H is Shannon's H; k(B) the Boltzmann constant ( 1.381 * 10^-33 J/K), 
</em><br />
<em class="quotelev2">&gt; &gt;and S the thermodynamic entropy in J/K. I am not a physicists, but I 
</em><br />
<em class="quotelev2">&gt; &gt;just answered the question. The derivation is provided by Ebeling. I 
</em><br />
<em class="quotelev2">&gt; &gt;can reproduce it if you wish.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;Otherwise, I agreed largely with Michel's introductory 
</em><br />
<em class="quotelev1">&gt; paper. I don't 
</em><br />
<em class="quotelev2">&gt; &gt;understand your formula of Delta S &gt; - Delta I. How is I 
</em><br />
<em class="quotelev1">&gt; defined? Can 
</em><br />
<em class="quotelev2">&gt; &gt;you give the formula? (Your second email was even more confusing.)
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;With kind regards,
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;Loet
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;  _____
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;Loet Leydesdorff
</em><br />
<em class="quotelev2">&gt; &gt;Amsterdam School of Communications Research (ASCoR)
</em><br />
<em class="quotelev2">&gt; &gt;Kloveniersburgwal 48, 1012 CX Amsterdam
</em><br />
<em class="quotelev2">&gt; &gt;Tel.: +31-20- 525 6598; fax: +31-20- 525 3681 
</em><br />
<em class="quotelev2">&gt; &gt; &lt;mailto:loet&#64;leydesdorff.net&gt; loet&#64;leydesdorff.net ;
</em><br />
<em class="quotelev2">&gt; &gt;&lt;<a href="../../www.leydesdorff.net/default.htm">http://www.leydesdorff.net/</a>&gt; <a href="../../www.leydesdorff.net/default.htm">http://www.leydesdorff.net/</a> 
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; 
</em><br />
<em class="quotelev2">&gt; &gt; &lt;<a href="../../www.upublish.com/books/leydesdorff-sci.htm">http://www.upublish.com/books/leydesdorff-sci.htm</a>&gt; The 
</em><br />
<em class="quotelev1">&gt; Challenge of 
</em><br />
<em class="quotelev2">&gt; &gt;Scientometrics ;  
</em><br />
<em class="quotelev1">&gt; &lt;<a href="../../www.upublish.com/books/leydesdorff.htm">http://www.upublish.com/books/leydesdorff.htm</a>&gt; The 
</em><br />
<em class="quotelev2">&gt; &gt;Self-Organization of the Knowledge-Based Society
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;-----Original Message-----
</em><br />
<em class="quotelev3">&gt; &gt;&gt;From: fis-bounces&#64;listas.unizar.es
</em><br />
<em class="quotelev3">&gt; &gt;&gt;[ &lt;mailto:fis-bounces&#64;listas.unizar.es&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev2">&gt; &gt;mailto:fis-bounces&#64;listas.unizar.es] On Behalf Of Dr. Shu-Kun Lin
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Sent: Monday, April 05, 2004 3:53 PM
</em><br />
<em class="quotelev3">&gt; &gt;&gt;To: fis&#64;listas.unizar.es
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Subject: Re: [Fis] FIS / introductory text / 5 April 2004
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Dear Loet,
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;You mean entropy S is equal to information (I), or almost 
</em><br />
<em class="quotelev1">&gt; equal. Can 
</em><br />
<em class="quotelev3">&gt; &gt;&gt;you still give
</em><br />
<em class="quotelev3">&gt; &gt;&gt;a little bit of sympathy to the relation that Delta S &gt; - Delta
</em><br />
<em class="quotelev3">&gt; &gt;&gt;(information) and make some
</em><br />
<em class="quotelev3">&gt; &gt;&gt;comments on this different relation? If we can agree on the
</em><br />
<em class="quotelev3">&gt; &gt;&gt;relation that Delta S &gt; - Delta (information), then we are
</em><br />
<em class="quotelev3">&gt; &gt;&gt;ready to ask &quot;why information loss is related to entropy&quot;, a
</em><br />
<em class="quotelev3">&gt; &gt;&gt;question asked by
</em><br />
<em class="quotelev3">&gt; &gt;&gt;physicists at the
</em><br />
<em class="quotelev3">&gt; &gt;&gt; &lt;<a href="../../www.lns.cornell.edu/spr/2000-12/msg0030047.html">http://www.lns.cornell.edu/spr/2000-12/msg0030047.html</a>&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev2">&gt; &gt;<a href="../../www.lns.cornell.edu/spr/2000-12/msg0030047.html">http://www.lns.cornell.edu/spr/2000-12/msg0030047.html</a>
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;website, and try to answer.
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Michel, thank you for your introduction.
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Shu-Kun
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Loet Leydesdorff wrote:
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Dear Michel,
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;The relation between thermodynamic entropy and the information is 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;provided by the Szilard-Brillouin relation as follows:
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Delta S &gt;= k(B) Delta H
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;(W. Ebeling. Chaos, Ordnung und Information. Frankfurt a.M.: Harri 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Deutsch Thun, 1991, at p. 60.)
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;k(B) in this formula is the Boltzmann constant. Thus, a
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;physical change
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;of the system can provide an information, but it does not have to. 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Unlike the thermodynamic entropy, probabilistic entropy has no 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;dimensionality (because it is mathematically defined). The 
</em><br />
<em class="quotelev1">&gt; Boltmann 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;constant takes care of the correction in the dimensionality in the 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;equation.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;When applied as a statistics to other systems (e.g.,
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;biological ones)
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;one obtains another (specific) theory of communication in
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;which one can
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;perhaps find another relation between the (in this case 
</em><br />
<em class="quotelev1">&gt; biological) 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;information and the probabilistic entropy. This can be
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;elaborated for
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;each specific domain.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;With kind regards,
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Loet
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt; _____
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Loet Leydesdorff
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Science &amp; Technology Dynamics, University of Amsterdam
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Amsterdam School
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;of Communications Research (ASCoR) Kloveniersburgwal 48, 1012 CX
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Amsterdam
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Tel.: +31-20-525 6598; fax: +31-20-525 3681 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;&lt; &lt;mailto:loet&#64;leydesdorff.net&gt; mailto:loet&#64;leydesdorff.net&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt; &gt;loet&#64;leydesdorff.net;
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;&lt; &lt;<a href="../../www.leydesdorff.net/default.htm">http://www.leydesdorff.net/</a>&gt; <a href="../../www.leydesdorff.net/default.htm">http://www.leydesdorff.net/</a>&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt; &gt;&lt;<a href="../../www.leydesdorff.net/default.htm">http://www.leydesdorff.net</a>&gt; <a href="../../www.leydesdorff.net/default.htm">http://www.leydesdorff.net</a>
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;-----Original Message-----
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;From: fis-bounces&#64;listas.unizar.es
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;[ &lt;mailto:fis-bounces&#64;listas.unizar.es&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt; &gt;mailto:fis-bounces&#64;listas.unizar.es]
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;On Behalf Of Michel Petitjean
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Sent: Monday, April 05, 2004 9:15 AM
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;To: fis&#64;listas.unizar.es
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Subject: [Fis] FIS / introductory text / 5 April 2004
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;2004 FIS session introductory text.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Dear FISers,
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;I would like to thank Pedro Marijuan for his kind invitation
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;to chair
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;the 2004 FIS session. The session is focussed on &quot;Entropy and 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Information&quot;. It is vast, that I am afraid to be able only 
</em><br />
<em class="quotelev1">&gt; to evoke 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;some general aspects, discarding specific technical developments.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;    Entropy and Information: two polymorphic concepts.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Although these two concepts are undoubtly related, they have
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;different
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;stories.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Let us consider first the Information concept.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;There was many discussions in the FIS list about the meaning of 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Information. Clearly, there are several definitions. The 
</em><br />
<em class="quotelev1">&gt; information 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;concept that most people have in mind is outside the scope of this
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;text: is it born with Computer Sciences, or is it born with
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Press, or
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;does it exist since a so long time that nobody could date it? 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Neglecting the definitions from the dictionnaries (for 
</em><br />
<em class="quotelev1">&gt; each language 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;and culture), I would say that anybody has his own concept. 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Philosophers and historians have to look. The content of the FIS 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;archives suggests that the field is vast.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Now let us look to scientific definitions. Those arising from 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;mathematics are rigorous, but have different meanings. An 
</em><br />
<em class="quotelev1">&gt; example is 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;the information concept emerging from information theory (Hartley, 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Wiener, Shannon, Renyi,...). This concept, which arises from 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;probability theory, has little connections with the Fisher
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;information,
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;which arises also from probability theory. The same word is
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;used, but
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;two rigorous concepts are defined. One is mostly related to coding 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;theory, and the other is related to estimation theory. One
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;deals mainly
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;with non numerical finite discrete distributions, and the other is 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;based on statistics from samples of parametrized family of 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;distributions. Even within the framework of information
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;theory, there
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;are several definitions of information (e.g. see the last 
</em><br />
<em class="quotelev1">&gt; chapter of 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Renyi's book on Probability Theory). This situation arises often in
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;mathematics: e.g., there are several concepts of &quot;distance&quot;, and, 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;despite the basic axioms they all satisfy, nobody would say
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;that they
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;have the same meaning, even when they are defined on a 
</em><br />
<em class="quotelev1">&gt; common space.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Then, mathematical tools are potential (and sometimes 
</em><br />
<em class="quotelev1">&gt; demonstrated) 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;simplified models for physical phenomenons. On the other hand, 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;scientists may publish various definitions of information
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;for physical
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;situations. It does not mean that any of these definitions 
</em><br />
<em class="quotelev1">&gt; should be 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;confused between themselves and confused with the
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;mathematical ones. In
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;many papers, the authors insist on the analogies between their own 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;concepts and those previously published by other authors:
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;this attitude
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;may convince the reviewers of the manuscript that the work has 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;interest, but contribute to the general confusion, 
</em><br />
<em class="quotelev1">&gt; particularly when 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;the confusing terms are recorded in the bibliographic databases. 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Searching in databases with the keyword &quot;information&quot; would
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;lead to a
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;considerable number of hits: nobody would try it without
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;constraining
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;the search with other terms (did some of you tried?).
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;We consider now the Entropy concepts. The two main ones are the 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;informational entropy and the thermodynamical entropy. The 
</em><br />
<em class="quotelev1">&gt; first one 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;has non ambiguous relations with information (in the sense of 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;information theory), since both are defined within the
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;framework of a
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;common theory. Let us look now to the thermodynamical 
</em><br />
<em class="quotelev1">&gt; entropy, which 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;was defined by Rudolf Clausius in 1865. It is a physical concept, 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;usually introduced from the Carnot Cycle. The existence of
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;entropy is
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;postulated, and it is a state function of the system. Usual
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;variables
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;are temperature and pressure. Entropy calculations are
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;sometimes made
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;discarding the implicit assumptions done for an idealized
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Carnot Cycle.
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Here come difficulties. E.g., the whole universe is sometimes 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;considered as a system for which the the entropy is 
</em><br />
<em class="quotelev1">&gt; assumed to have 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;sense. Does the equilibrium of such a system has sense? Does 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;thermodynamical state functions make sense here? And what
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;about &quot;the&quot;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;temperature? These latter variable, even when viewed as a
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;function of
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;coordinates and/or time, has sense only for a restricted number of 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;situations. These difficulties appear for many other
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;systems. At other
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;scales, they may appear for microscopic systems, and for 
</em><br />
<em class="quotelev1">&gt; macroscopic 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;systems unrelated to thermochemistry. In fact, what is often
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;implicitly
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;postulated is that the thermodynamical entropy theory could work 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;outside thermodynamics.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Statistical mechanics creates a bridge between microscopic and 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;macroscopic models, as evidenced from the work of Boltzmann.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;These two
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;models are different. One is a mathematical model for an idealized 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;physical situation (punctual balls, elastic collisions,
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;distribution of
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;states, etc..), and the other is a simplified physical
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;model, working
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;upon a restricted number of conditions. The expression of
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;the entropy,
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;calculated via statistical mechanics methods, is formally 
</em><br />
<em class="quotelev1">&gt; similar to 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;the informational entropy. This latter has appeared many
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;decades after
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;the former. Thus, the pioneers of information theory (Shannon, von
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Neumann) who retain the term &quot;entropy&quot;, are undoubtly 
</em><br />
<em class="quotelev1">&gt; responsible of 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;the historical link between &lt;&lt;Entropy&gt;&gt; and &lt;&lt;Information&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;(e.g. see
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;&lt;<a href="../../www.bartleby.com/64/C004/024.html">http://www.bartleby.com/64/C004/024.html</a>&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt; &gt;<a href="../../www.bartleby.com/64/C004/024.html">http://www.bartleby.com/64/C004/024.html</a>).
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Although &quot;entropy&quot; is a well known term in information
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;theory, and used
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;coherently with the term &quot;information&quot; in this area, the
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;situation is
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;different in science. I do not know what is &quot;information&quot; in 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;theermodynamics (does anybody know?). However, &quot;chemical
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;information&quot;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;is a well known area of chemistry, which covers many topics,
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;including
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;data mining in chemical data bases. In fact, chemical
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;information was
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;reognized as a major field when the ACS decided in 1975 to
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;rename one
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;of its journals &quot;Journal of Chemical Information and Computer
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Sciences&quot;: it was previously named the &quot;Journal of Chemical 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Documentation&quot;. There are little papers in this journal which are 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;connected with entropy (thermodunamical of informational).
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;An example
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;is the 1996 paper of Shu-Kun Lin, relating entropy with
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;similarity and
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;symmetry. Similarity is itself a major area in chemical 
</em><br />
<em class="quotelev1">&gt; information, 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;but I consider that the main area of chemical information is
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;related to
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;chemical databases, such that the chemical information is
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;represented
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;by the nodes and edges graph associated to a structural formula. 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Actually, mathematical tools able to work on this kind of chemical 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;information are lacking, particulary for statistics (did anyone 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;performed statistics on graphs?).
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;In 1999, the links between information sciences and entropy
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;were again
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;recognized, when Shu-Kun lin created the open access journal
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;&quot;Entropy&quot;:
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;&lt;&lt;An International and Interdisciplinary Journal of Entropy and 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Information Studies&gt;&gt;. Although most pluridisciplinary
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;journals are at
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;the intersection of two areas, Shu-Kun Lin is a pionneer in
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;the field
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;of transdisciplinarity, permitting the publication in a
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;single journal
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;of works related to entropy and/or information theory,
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;originating from
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;mathematics, physics, chemistry, biology, economy, and philosophy.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;The concept of information exists in other sciences for
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;which the term
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;entropy is used. Bioinformation is a major concept in
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;bioinformatics,
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;for which I am not specialist. Thus I hope that Pedro 
</em><br />
<em class="quotelev1">&gt; Marijuan would 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;like to help us to understand what are the links between
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;bioinformation
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;and entropy. Entropy and information are known from economists and 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;philosophers. I also hope they add their voice to those of
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;scientists
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;and mathematicians, to enlight our discussions during the session.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Now I would like to draw some provocative conclusions. Analogies 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;between concepts or between formal expressions of quantities
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;are useful
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;for the spirit, for the quality of the papers, and sometimes
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;they are
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;used by modellers to demonstrate why their work merit funds (does 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;anybody never do that?). The number of new concepts in sciences 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;(includes mathematics, economy, humanities, and so on) is
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;increasing,
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;and new terms are picked in our natural language: the task of the 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;teachers becomes harder and harder. Entropy and 
</em><br />
<em class="quotelev1">&gt; Information are like 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;the &quot;fourth dimension&quot;, one century ago: they offer in common the 
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;ability to provide exciting topics to discuss.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;Unfortunately, Entropy
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;and Information are much more difficult to handle.
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Michel Petitjean                      Email:
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt;petitjean&#64;itodys.jussieu.fr
</em><br />
<em class="quotelev3">&gt; &gt;&gt;    
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;Editor-in-Chief of Entropy                   entropy&#64;mdpi.org
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;ITODYS (CNRS, UMR 7086)                      
</em><br />
<em class="quotelev1">&gt; ptitjean&#64;ccr.jussieu.fr
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;1 rue Guy de la Brosse                Phone: +33 (0)1 44 27 48 57
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;75005 Paris, France.                  FAX  : +33 (0)1 44 27 68 14
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;&lt;<a href="../../www.mdpi.net/default.htm">http://www.mdpi.net</a>&gt; <a href="../../www.mdpi.net/default.htm">http://www.mdpi.net</a>
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt; &gt;&lt;<a href="../../www.mdpi.org/default.htm">http://www.mdpi.org</a>&gt; <a href="../../www.mdpi.org/default.htm">http://www.mdpi.org</a>
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;&lt;<a href="../../petitjeanmichel.free.fr/itoweb.petitjean.html">http://petitjeanmichel.free.fr/itoweb.petitjean.html</a>&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt; &gt;<a href="../../petitjeanmichel.free.fr/itoweb.petitjean.html">http://petitjeanmichel.free.fr/itoweb.petitjean.html</a>
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;&lt;<a href="../../petitjeanmichel.free.fr/itoweb.petitjean.freeware.html">http://petitjeanmichel.free.fr/itoweb.petitjean.freeware.html</a>&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt; &gt;<a href="../../petitjeanmichel.free.fr/itoweb.petitjean.freeware.html">http://petitjeanmichel.free.fr/itoweb.petitjean.freeware.html</a>
</em><br />
<em class="quotelev2">&gt; &gt;  
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;_______________________________________________
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;fis mailing list
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;fis&#64;listas.unizar.es  
</em><br />
<em class="quotelev1">&gt; &lt;<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>&gt;
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;      
</em><br />
<em class="quotelev4">&gt; &gt;&gt;&gt;
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt;<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;      
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;--
</em><br />
<em class="quotelev2">&gt;&gt;Dr. Shu-Kun Lin
</em><br />
<em class="quotelev2">&gt;&gt;Molecular Diversity Preservation International (MDPI) Matthaeusstrasse
</em><br />
<p><em class="quotelev2">&gt;&gt;11, CH-4057 Basel, Switzerland Tel. +41 61 683 7734 (office) Tel. +41 
</em><br />
<em class="quotelev2">&gt;&gt;79 322 3379 (mobile) Fax +41 61 302 8918
</em><br />
<em class="quotelev2">&gt;&gt;E-mail: lin&#64;mdpi.org
</em><br />
<em class="quotelev2">&gt;&gt; &lt;<a href="../../www.mdpi.org/lin/default.htm">http://www.mdpi.org/lin/</a>&gt; <a href="../../www.mdpi.org/lin/default.htm">http://www.mdpi.org/lin/</a>
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;_______________________________________________
</em><br />
<em class="quotelev2">&gt;&gt;fis mailing list
</em><br />
<em class="quotelev2">&gt;&gt;<a href="mailto:fis&#64;listas.unizar.es?Subject=RE:%20[Fis]%20FIS%20/%20introductory%20text%20/%205%20April%202004">fis@listas.unizar.es</a>  &lt;<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>&gt;
</em><br />
<em class="quotelev2">&gt;&gt;    
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev1">&gt;<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;
</em><br />
<p><pre>
-- 
Dr. Shu-Kun Lin
Molecular Diversity Preservation International (MDPI) Matthaeusstrasse
11, CH-4057 Basel, Switzerland Tel. +41 61 683 7734 (office) Tel. +41 79
322 3379 (mobile) Fax +41 61 302 8918
E-mail: lin&#64;mdpi.org
<a href="../../www.mdpi.org/lin/default.htm">http://www.mdpi.org/lin/</a>
_______________________________________________
fis mailing list
<a href="mailto:fis&#64;listas.unizar.es?Subject=RE:%20[Fis]%20FIS%20/%20introductory%20text%20/%205%20April%202004">fis@listas.unizar.es</a> <a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
_______________________________________________
fis mailing list
fis&#64;listas.unizar.es
<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
</pre>
<span id="received"><dfn>Received on</dfn> Mon Apr  5 20:40:48 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1400.html" title="Next message in the list">Michael Devereux: "[Fis] Szilard's Engine and Information"</a></li>
<li><dfn>Previous message</dfn>: <a href="1398.html" title="Previous message in the list">Dr. Shu-Kun Lin: "Re: [Fis] FIS / introductory text / 5 April 2004"</a></li>
<li><dfn>In reply to</dfn>: <a href="1398.html" title="Message to which this message replies">Dr. Shu-Kun Lin: "Re: [Fis] FIS / introductory text / 5 April 2004"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1406.html" title="Next message in this discussion thread">Stanley N. Salthe: "Re: [Fis] FIS / introductory text / 5 April 2004"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1399" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1399" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1399" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1399" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:46 CET
</em></small></p>
</body>
</html>
