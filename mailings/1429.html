<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: [Fis] Probabalistic Entropy</title>
<meta name="Author" content="Michael Devereux (dbar_x@cybermesa.com)" />
<meta name="Subject" content="[Fis] Probabalistic Entropy" />
<meta name="Date" content="2004-04-16" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>[Fis] Probabalistic Entropy</h1>
<!-- received="Fri Apr 16 07:13:27 2004" -->
<!-- isoreceived="20040416051327" -->
<!-- sent="Thu, 15 Apr 2004 23:12:31 -0600" -->
<!-- isosent="20040416051231" -->
<!-- name="Michael Devereux" -->
<!-- email="dbar_x@cybermesa.com" -->
<!-- subject="[Fis] Probabalistic Entropy" -->
<!-- id="407F6B3F.2050804@cybermesa.com" -->
<!-- charset="windows-1252" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1430.html" title="Loet Leydesdorff: &quot;RE: [Fis] Probabalistic Entropy&quot;">Next message</a> ]
[ <a href="1428.html" title="Shu-Kun Lin: &quot;Re: [Fis] Szilard's Engine and Information&quot;">Previous message</a> ]
<!-- unextthread="start" -->
[ <a href="1430.html" title="Loet Leydesdorff: &quot;RE: [Fis] Probabalistic Entropy&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Michael Devereux &lt;<a href="mailto:dbar_x&#64;cybermesa.com?Subject=Re:%20[Fis]%20Probabalistic%20Entropy">dbar_x@cybermesa.com</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri 16 Apr 2004 - 07:12:31 CEST</span><br />
</address>
<p>
Colleagues,
<br />
<p>I appreciate the opportunity of this forum to consider some of the 
<br />
fascinating and stimulating ideas that have been expressed recently in 
<br />
postings. It’s a pleasure for a scientist to discuss with both 
<br />
scientists and nonscientists these interesting notions.
<br />
Loet wrote that “the Shannon entropy is the more interesting part” and 
<br />
“the Shannon entropy is more general because it can be applied to 
<br />
systems other than the physical one” and “the mathematical richness is 
<br />
available because Shannon chose H and the algorithms of physics can thus 
<br />
be used as a heuristic for the computation in other systems”. Also, 
<br />
“these forms of organization (and self-organization) can be studied in 
<br />
terms of their probabilistic entropy.”
<br />
Thanks, Loet, for making the argument so forcefully. I agree. I think 
<br />
all the forms of entropy used by scientists can be expressed, 
<br />
fundamentally, as probabilities. Even the seemingly primitive form of 
<br />
Clausius’ version, Delta-Q / T, I believe, rests on a probabilistic 
<br />
foundation. Because heat is really microscopic motion, it’s always more 
<br />
probable that heat will flow spontaneously from the higher to the lower 
<br />
temperature. And I understand Boltzmann’s concept of entropy, in terms 
<br />
of available phase space, to really be about the PROBABILITY that 
<br />
physical systems, when unconstrained, are likely to move into the entire 
<br />
range of motion available to them. I understand that Boltzmann also 
<br />
thought of his description in terms of it’s probability.
<br />
Von Neumann derived an equation for quantum mechanics identical to 
<br />
Shannon’s. I expect many of you know that quantum mechanics speaks only 
<br />
to the probability of the outcome of physical events; that the 
<br />
particular outcome of a given observation is not knowable except as a 
<br />
probability for one or another result. Yet, we physicists have found 
<br />
that quantum mechanics describes all the known physical universe we see, 
<br />
from elementary microscopic particles to cosmological structures.
<br />
Aleks wrote that “Clausius’ (thermodynamic) entropy is very different 
<br />
from Shannon’s entropy,” and “Thermodynamic entropy is something one can 
<br />
measure. Shannon’s entropy is instead a general one.” If I understand 
<br />
you, Aleks, I disagree. I’m convinced that the Shannon-von Neumann 
<br />
formula for entropy may be compared to the results of laboratory 
<br />
experiments also. It’s usual to do that for elementary particle 
<br />
experiments, like those at the CERN accelerator in Switzerland, for 
<br />
example.
<br />
Now, after decades of matching experimental observations, from 
<br />
elementary particles, from molecular measurements and solid-state 
<br />
phenomena, electronic devices and macroscopic interference effects, even 
<br />
from innumerable astronomical observations, to the probabilistic 
<br />
predictions of quantum mechanics, I believe that the probabilistic 
<br />
formulation of entropy is the general one. It works for heat engines 
<br />
also, as Szilard’s engine exemplifies.
<br />
Broadly speaking, I think that it’s the tendency of the physical 
<br />
universe to move toward its most probable state which accounts for the 
<br />
heat exhausted by machines, the persistent problems of cleaning up after 
<br />
ourselves, the understanding that our universe must have been more 
<br />
“orderly” at its conception, and all those other observations 
<br />
unidirectional in time.
<br />
So, I’ve got to disagree with the sentiment expressed in Bob’s wonderful 
<br />
posting that “thermodynamics rests on a phenomenological foundation that 
<br />
is far more solid than any atomic “hypothesis.” It’s my view, Bob, that 
<br />
entropy is pertinent to all physical phenomena, and it can be of 
<br />
fundamental importance for all of them. Pertinent to the microscopic, 
<br />
ordinarily observable, and even cosmological events we describe, as well 
<br />
as the engines, and such, envisioned by Carnot and Maxwell.
<br />
I expect, Loet, that by systems other than the physical one, you mean 
<br />
those systems not traditionally described by physics. You mention 
<br />
circulation of money in an economy, the division of classes in a school, 
<br />
the characters in a Boltzmann machine at temperatures above zero K, and 
<br />
living systems. I usually conceive of physical systems as tangible, 
<br />
observable ones; systems that impress our human senses. So, I tend to 
<br />
categorize all the systems you’ve mentioned as physical ones. I trust I 
<br />
understand your idea, Loet.
<br />
According to von Neumann’s prescription, the mathematical model of 
<br />
quantum mechanics meets the observable physical universe through 
<br />
comparison of an ensemble of prepared experiments with the probabilistic 
<br />
predictions of the mathematics. I understand all of physics to operate 
<br />
in exactly that way. That we make models of everything we observe, and 
<br />
then evaluate those models experimentally. Is it true that all of 
<br />
science follows that scheme?
<br />
I expect, Aleks, that you mean much the same thing when you say that 
<br />
Boltzmann’s model for entropy is “just a paradigm (model, not measure). 
<br />
It was tested, and it was proved that the paradigm is not misguided.” I 
<br />
know that physicists must spend what seems an inordinate amount of time 
<br />
in university laboratories, trying to become physicists, so, essentially 
<br />
all the ones I’ve known, have a palpable, ponderable, almost visceral 
<br />
respect for the distinction between theoretical models of nature and 
<br />
those validating observations.
<br />
We divide ourselves, usually, into theoretical or experimental 
<br />
physicists. But all of us, in my experience, understand that measurement 
<br />
is the criterion by which theories are judged, and that observations are 
<br />
never, ever, as clean, elegant, or precise as their mathematical model. 
<br />
I’ve found it often a frustrating, unsanitary business trying to make 
<br />
measurement equipment give up some useful numbers. Sound familiar?
<br />
Thanks, Aleks, for the direction to Denis Evans work. I’ll read it. It’s 
<br />
usual, though, isn’t it, to expect fluctuations away from the most 
<br />
probable state to decrease with the increase in system size? So that’s 
<br />
not new, is it? And Boltzmann’s H theorem says that thermodynamic 
<br />
systems evolve toward equilibrium. So, that’s not novel either, is it? 
<br />
Zurek’s paper on the Szilard engine claims to solve any fluctuation 
<br />
problems with the engine. I believe him. Do you disagree with his analysis?
<br />
Thanks for the stimulating ideas.
<br />
Cordially,
<br />
<p>Michael Devereux (dbar_x&#64;cybermesa.com)
<br />
<p>_______________________________________________
<br />
fis mailing list
<br />
fis&#64;listas.unizar.es
<br />
<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
<br />
<span id="received"><dfn>Received on</dfn> Fri Apr 16 07:13:27 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1430.html" title="Next message in the list">Loet Leydesdorff: "RE: [Fis] Probabalistic Entropy"</a></li>
<li><dfn>Previous message</dfn>: <a href="1428.html" title="Previous message in the list">Shu-Kun Lin: "Re: [Fis] Szilard's Engine and Information"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1430.html" title="Next message in this discussion thread">Loet Leydesdorff: "RE: [Fis] Probabalistic Entropy"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1430.html" title="Message sent in reply to this message">Loet Leydesdorff: "RE: [Fis] Probabalistic Entropy"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1429" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1429" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1429" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1429" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:46 CET
</em></small></p>
</body>
</html>
