<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: [Fis] Shannon said Information is Physical Entropy</title>
<meta name="Author" content="Michael Devereux (dbar_x@cybermesa.com)" />
<meta name="Subject" content="[Fis] Shannon said Information is Physical Entropy" />
<meta name="Date" content="2004-06-17" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>[Fis] Shannon said Information is Physical Entropy</h1>
<!-- received="Thu Jun 17 06:29:19 2004" -->
<!-- isoreceived="20040617042919" -->
<!-- sent="Wed, 16 Jun 2004 22:26:14 -0600" -->
<!-- isosent="20040617042614" -->
<!-- name="Michael Devereux" -->
<!-- email="dbar_x@cybermesa.com" -->
<!-- subject="[Fis] Shannon said Information is Physical Entropy" -->
<!-- id="40D11D66.8010805@cybermesa.com" -->
<!-- charset="windows-1252" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1597.html" title="Gyorgy Darvas: &quot;Re: [Fis] 2004 FIS session: concluding comments&quot;">Next message</a> ]
[ <a href="1595.html" title="Stanley N. Salthe: &quot;Re: [Fis] 2004 FIS session: concluding comments&quot;">Previous message</a> ]
<!-- unextthread="start" -->
[ <a href="1598.html" title="Loet Leydesdorff: &quot;RE: [Fis] Shannon said Information is Physical Entropy&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Michael Devereux &lt;<a href="mailto:dbar_x&#64;cybermesa.com?Subject=Re:%20[Fis]%20Shannon%20said%20Information%20is%20Physical%20Entropy">dbar_x@cybermesa.com</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Thu 17 Jun 2004 - 06:26:14 CEST</span><br />
</address>
<p>
Dear Werner, Loet and colleagues,
<br />
<p>I hope I don’t seem merely argumentative. It’s not my intention to keep 
<br />
saying the same thing over and over until no one else is willing to 
<br />
rebut my assertions. The ideas we’re discussing are most significant to 
<br />
me because, among other things, they play a crucial role in calculations 
<br />
I’m completing on the entropy cost of information processing in 
<br />
Szilard’s engine. I hope to be able to determine, definitively, the 
<br />
entropy cost of manipulating individual information bits.
<br />
<p>So, I’d like to sustain those claims I continue to believe are 
<br />
scientifically valid and truly important. I’m not looking for agreement 
<br />
with all my colleagues, but, rather, the good science of agreement with 
<br />
physical reality. And, I welcome the informed and considered criticism 
<br />
of everyone who disagrees.
<br />
<p>In that light, I think the most important question is whether Shannon 
<br />
entropy (as Shannon derived and understood it, not simply as that term 
<br />
may be used in each research investigation) is the same thing as 
<br />
physical (thermodynamic) entropy. I understand that many in this forum 
<br />
would answer this question with a no. Werner, you’ve written that 
<br />
Shannon entropy and Boltzmann’s physical entropy are “not completely 
<br />
separated, but related.”
<br />
<p>Shannon co-wrote a book with Warren Weaver a year after publication of 
<br />
his famous equation derivation. It’s called “The Mathematical Theory of 
<br />
Communication” (University of Illinois Press, Chicago, 1949). Weaver 
<br />
writes that “The quantity which uniquely meets the natural requirements 
<br />
that one sets up for ‘information’ turns out to be exactly that which is 
<br />
known in thermodynamics as entropy....That information be measured by 
<br />
entropy, is, after all, natural when we remember that information, in 
<br />
communication theory, is associated with the amount of freedom of choice 
<br />
we have in constructing messages.” (pp. 12-13). Weaver tells us that 
<br />
this information is modeled by Shannon’s infamous equation, H = - Sum p 
<br />
log (p) (page 14).
<br />
<p>I previously cited Grandy’s resource letter (Am. J. Phys. 65, 6, 1997, 
<br />
p. 466). He tells us that the “rigorous connection of information theory 
<br />
to physics” is due to Jaynes (Phys. Rev. A 106, 1957, p. 620) who showed 
<br />
that S (physical entropy) “measures the amount of information about the 
<br />
microstate conveyed by data on macroscopic thermodynamic variables,” 
<br />
where S is the “experimental entropy of Clausius. Quantum mechanically 
<br />
one employs the density matrix rho and von Neumann’s form of the 
<br />
entropy” (p. 469).
<br />
<p>I’ve continued to maintain in this forum Landauer’s contention that 
<br />
information is physical ( Landauer, Phys. Today, May 1991, Landauer, 
<br />
Phys. Lett. A, 217, 1996, p. 188. Sorry, Aleks, I had thought these 
<br />
publications were decades earlier.) Other authors have made the same 
<br />
argument. And, if it’s true that information is physical, then Shannon, 
<br />
obviously, was deriving an equation for something physical. I’ve 
<br />
previously quoted Shannon here in this forum: “We wish to consider 
<br />
certain general problems involving communication systems. To do this it 
<br />
is first necessary to represent the various elements involved as 
<br />
mathematical entities, suitably idealized from their physical 
<br />
counterparts.”
<br />
<p>I know it’s a repeat of a repeat, but I think the distinction between 
<br />
the thing being described (the thing itself, whether the energy of a 
<br />
physical particle or, say, the idiosyncratic behavior of some species of 
<br />
bird, or Shannon entropy), and the mathematical model of that thing, is 
<br />
an essential distinction to maintain. As Michel has said, we all seem to 
<br />
be able to recognize that difference. Would you disagree, Werner? You 
<br />
write that Shannon entropy is truly pure mathematics, that “it is a 
<br />
mathematical expression which can be applied to many systems having 
<br />
probability distributions.” (I emphasize the word “entropy”, as opposed 
<br />
to “equation”, or “mathematical expression”.) Perhaps you don’t permit a 
<br />
difference between Shannon’s equation and Shannon entropy, Werner.
<br />
<p>As an analogy, energy is a measurable property of tangible objects, and 
<br />
is not the same thing as the mathematical formula which describes 
<br />
kinetic energy or electrical energy, etc. (We physicists cringe when 
<br />
“New-Age Astrologers”, for example, predict the heightened energy of 
<br />
personal relationships that must result from the conjunction of Venus 
<br />
and Mars in Virgo. We don’t permit the word energy with that meaning in 
<br />
science. I believe that restriction is entirely worthwhile within our 
<br />
own scientific disciplines because it fosters precise understanding of 
<br />
the concept, which can then be modeled mathematically.)
<br />
<p>I understand, Loet, that “Shannon’s formula is a mathematical expression 
<br />
that is formally similar to the Boltzmann equation.” But, as Shannon and 
<br />
Weaver, and Jaynes, and Landauer have shown us, Shannon entropy is the 
<br />
same physical thing as thermodynamic entropy. So, with Shannon’s 
<br />
entropy, anyway, I don’t agree that “the reference to a physical system 
<br />
is possible, but not necessary.”
<br />
<p>And, if Shannon entropy is actually physical entropy then it must obey 
<br />
the Second Law of Thermodynamics. If it’s not increasing monotonically 
<br />
with increasing N, it’’s not really Shannon entropy. And if won’t 
<br />
satisfy the monotonically increasing postulate that Shannon imposed on 
<br />
his derivation.
<br />
.
<br />
Is it perhaps dogmatic, Loet, to insist that Shannon entropy is what 
<br />
Shannon said it was? I believe restriction to that meaning avoids 
<br />
confusion in our research. To my mind, “Shannon entropy” is a technical 
<br />
term, just like energy, or cell mitosis. And we promote understanding, 
<br />
rather than confusion, by calling something Shannon entropy only if it 
<br />
means what Shannon meant. That was my point in arguing that a Devereux 
<br />
theory, or a Leydesdorff theory, ought to be what you or I have stated 
<br />
our own theory to be. My feeling is that we ought to label it with a 
<br />
different name if it isn’t actually the author’s meaning we intend by 
<br />
that name.
<br />
<p>You’ve written, Werner, that “applying Shannon’s formula to physical 
<br />
systems not necessarily gives thermodynamic entropy”. I think that can 
<br />
be a confusing problem if one labels the property of that physical 
<br />
system Shannon entropy. Simply employing Shannon’s formula on the system 
<br />
does not guarantee that the property being modeled is Shannon entropy. 
<br />
That’s one of the arguments I was trying to defend in recent postings. 
<br />
You said “there are applications to physical systems....which lead to 
<br />
some entropy but not to the measurable thermodynamic entropy.” And I 
<br />
suggest, as scientists, we never call that thing Shannon entropy.
<br />
<p>I’m grateful for the comments which prompt me to reconsider, and, 
<br />
hopefully, further understand these important concepts.
<br />
<p>Cordially,
<br />
<p>Michael Devereux
<br />
<p><p><p>_______________________________________________
<br />
fis mailing list
<br />
fis&#64;listas.unizar.es
<br />
<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
<br />
<span id="received"><dfn>Received on</dfn> Thu Jun 17 06:29:19 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1597.html" title="Next message in the list">Gyorgy Darvas: "Re: [Fis] 2004 FIS session: concluding comments"</a></li>
<li><dfn>Previous message</dfn>: <a href="1595.html" title="Previous message in the list">Stanley N. Salthe: "Re: [Fis] 2004 FIS session: concluding comments"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1598.html" title="Next message in this discussion thread">Loet Leydesdorff: "RE: [Fis] Shannon said Information is Physical Entropy"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1598.html" title="Message sent in reply to this message">Loet Leydesdorff: "RE: [Fis] Shannon said Information is Physical Entropy"</a></li>
<li><dfn>Reply</dfn>: <a href="1599.html" title="Message sent in reply to this message">jakulin@acm.org: "RE: [Fis] Shannon said Information is Physical Entropy"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1596" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1596" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1596" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1596" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:46 CET
</em></small></p>
</body>
</html>
