<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: [Fis] Is it Shannon entropy?</title>
<meta name="Author" content="Michael Devereux (dbar_x@cybermesa.com)" />
<meta name="Subject" content="[Fis] Is it Shannon entropy?" />
<meta name="Date" content="2004-06-07" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>[Fis] Is it Shannon entropy?</h1>
<!-- received="Mon Jun  7 07:49:54 2004" -->
<!-- isoreceived="20040607054954" -->
<!-- sent="Sun, 06 Jun 2004 23:47:56 -0600" -->
<!-- isosent="20040607054756" -->
<!-- name="Michael Devereux" -->
<!-- email="dbar_x@cybermesa.com" -->
<!-- subject="[Fis] Is it Shannon entropy?" -->
<!-- id="40C4018C.4080700@cybermesa.com" -->
<!-- charset="windows-1252" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1566.html" title="Loet Leydesdorff: &quot;RE: [Fis] Is it Shannon entropy?&quot;">Next message</a> ]
[ <a href="1564.html" title="Devin Harris: &quot;Re: [Fis] Information and communication&quot;">Previous message</a> ]
<!-- unextthread="start" -->
[ <a href="1566.html" title="Loet Leydesdorff: &quot;RE: [Fis] Is it Shannon entropy?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Michael Devereux &lt;<a href="mailto:dbar_x&#64;cybermesa.com?Subject=Re:%20[Fis]%20Is%20it%20Shannon%20entropy?">dbar_x@cybermesa.com</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Mon 07 Jun 2004 - 07:47:56 CEST</span><br />
</address>
<p>
Dear Aleks, Loet and colleagues,
<br />
<p>I think many of us are using the same words to describe quite different 
<br />
things. It seems to me that the words information, entropy, Shannon 
<br />
entropy and Shannon information are being applied to properties that are 
<br />
not even under consideration within all the disciplines represented by 
<br />
all of us in this forum. I’ve never considered the application of 
<br />
Shannon’s formula to Loet’s currency transactions, or to Aleks’ medical 
<br />
patients, for example. And, I’m only slightly more familiar with how one 
<br />
might try to analyze information processing, or transfer, in living 
<br />
cells and organisms.
<br />
<p>I’m now sure from what I read in our forum, that the Shannon formula has 
<br />
a very extensive history of use in economics, medicine, biology, and 
<br />
many, many, other disciplines. And it appears that by the traditions and 
<br />
customs outside physics, if the Shannon formula is used to portray some 
<br />
pertinent property, then that property may be called Shannon entropy and 
<br />
Shannon information.
<br />
<p>But Shannon himself had something very specific in mind which he wished 
<br />
to describe mathematically. May I review again the actual history of 
<br />
Shannon’s work? I trust others may also recall that Shannon derived his 
<br />
famous entropy formula analytically from three initial postulates (Bell 
<br />
Sys. Tech. J. 28, 3, p. 379, 1948). Shannon said that the physical 
<br />
property he wished to describe mathematically (which he called entropy, 
<br />
“how uncertain we are of the outcome”), satisfied these three 
<br />
conditions. (Otherwise, of course, it’s not Shannon entropy.)
<br />
<p>The Shannon formula, H, is a statement of uniqueness. His equation is 
<br />
the only one that describes that physical property (entropy) which has 
<br />
those three characteristics depicted by mathematical postulates. The 
<br />
measure of how uncertain we are of an outcome, given probabilities, 
<br />
p-sub-i, for each possible result, must uniquely be the function, H = 
<br />
lambda (Sum p-sub-i log (p-sub-i)), where lambda is an arbitrary constant.
<br />
<p>So, what are these three postulates that uniquely determine the form of 
<br />
H? First, Shannon entropy will be continuous in the variables, p-sub-i. 
<br />
Second, in the simple case of maximum uncertainty, where all p-sub-i are 
<br />
equal to 1/N, Shannon entropy will be described as a MONOTONIC 
<br />
INCREASING FUNCTION OF N. The third postulate says that for two 
<br />
successive outcomes, the original value of the entropy must be the 
<br />
weighted sum of those two individual entropy values.
<br />
<p>I’d emphasize that if that property being described, does not increase 
<br />
monotonically, that property of the system is not Shannon’s entropy. 
<br />
Even though one may be using Shannon’s equation to describe it. (And 
<br />
that property of the system must also satisfy the other two postulates, 
<br />
if it really is Shannon entropy.) I mentioned in an earlier posting that 
<br />
at one end of a Shannon communication channel, the amount of information 
<br />
received can never be greater than the amount sent, though it may be 
<br />
less, if noise is present.
<br />
<p>Aleks wrote “we cannot infer ever-increasing entropy for Shannon's 
<br />
probabilistic model of communication, because this model has nothing to 
<br />
do with thermodynamical models.” I quoted Shannon previously in this 
<br />
forum, Aleks. Shannon wrote that “Quantities of the form H = Sum p log p 
<br />
play a central role in information theory as measures of information, 
<br />
choice and uncertainty. The form of H will be recognized as that of 
<br />
entropy as defined in certain formulations of statistical mechanics.... 
<br />
H is then, for example, the H in Boltzmann’s famous H theorem.” (p. 393) 
<br />
Perhaps, we must all accept Shannon’s own words as the authoritative and 
<br />
definitive resolution of this question.
<br />
<p>Aleks also wrote “Other fields introduce entropy and refer to 
<br />
thermodynamical laws, but often neglect to show that their underlying 
<br />
models show the same properties as those of statistical mechanics.” Of 
<br />
course, one can’t legislate the use of the term entropy only for a 
<br />
property of a system that satisfies all three of Shannon’s postulates. 
<br />
But I believe that if it doesn’t satisfy them, we must, as committed 
<br />
researchers, accept that such a thing is not Shannon entropy. But, if it 
<br />
does satisfy Shannon’s postulates, it is identical, as Shannon told us, 
<br />
with that entropy described by Clausius, Boltzmann and Plank.
<br />
<p>I don’t, for a moment, dismiss the extensive use and value of Shannon’s 
<br />
formula in economics, or linguistics, biology, or in any other 
<br />
discipline. Colleagues here have all made me aware of that history and 
<br />
tradition, and of the wide application of this formula to daunting, 
<br />
interesting problems. But, I would maintain that if Shannon’s own work 
<br />
concludes that some system characteristic isn’t actually Shannon 
<br />
entropy, then it’s not. Or, if it satisfies Shannon’s criteria, then it 
<br />
must be Clausius’ and Boltzmann’s entropy, as well as Shannon’s.
<br />
<p>I look forward to the valuable and considered responses that so many 
<br />
have here offered.
<br />
<p>Cordially,
<br />
Michael Devereux
<br />
<p><p><p><p><p><p><p><p><p><p><p><p><p>_______________________________________________
<br />
fis mailing list
<br />
fis&#64;listas.unizar.es
<br />
<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
<br />
<span id="received"><dfn>Received on</dfn> Mon Jun  7 07:49:54 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1566.html" title="Next message in the list">Loet Leydesdorff: "RE: [Fis] Is it Shannon entropy?"</a></li>
<li><dfn>Previous message</dfn>: <a href="1564.html" title="Previous message in the list">Devin Harris: "Re: [Fis] Information and communication"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1566.html" title="Next message in this discussion thread">Loet Leydesdorff: "RE: [Fis] Is it Shannon entropy?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1566.html" title="Message sent in reply to this message">Loet Leydesdorff: "RE: [Fis] Is it Shannon entropy?"</a></li>
<li><dfn>Reply</dfn>: <a href="1567.html" title="Message sent in reply to this message">jakulin@acm.org: "RE: [Fis] Is it Shannon entropy?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1565" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1565" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1565" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1565" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:46 CET
</em></small></p>
</body>
</html>
