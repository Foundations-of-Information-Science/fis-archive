<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta name="generator" content="hypermail 2.1.8, see http://www.hypermail.org/" />
<title>fis: Re: [Fis] Szilard's Engine and Information</title>
<meta name="Author" content="Dr. Shu-Kun Lin (lin@mdpi.org)" />
<meta name="Subject" content="Re: [Fis] Szilard's Engine and Information" />
<meta name="Date" content="2004-04-06" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
</style>
</head>
<body>
<div class="head">
<h1>Re: [Fis] Szilard's Engine and Information</h1>
<!-- received="Tue Apr  6 16:13:27 2004" -->
<!-- isoreceived="20040406141327" -->
<!-- sent="Tue, 06 Apr 2004 16:12:36 +0200" -->
<!-- isosent="20040406141236" -->
<!-- name="Dr. Shu-Kun Lin" -->
<!-- email="lin@mdpi.org" -->
<!-- subject="Re: [Fis] Szilard's Engine and Information" -->
<!-- id="4072BAD4.3050305@mdpi.org" -->
<!-- charset="windows-1252" -->
<!-- inreplyto="4071C260.6070509&#64;cybermesa.com" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ <a href="#options2">More options</a> ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1403.html" title="jakulin@acm.org: &quot;RE: [Fis] Szilard's Engine and Information&quot;">Next message</a> ]
[ <a href="1401.html" title="Pedro C. Marijuán: &quot;Re: [Fis] FIS / introductory text / 5 April 2004&quot;">Previous message</a> ]
[ <a href="1400.html" title="Michael Devereux: &quot;[Fis] Szilard's Engine and Information&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1419.html" title="Stanley N. Salthe: &quot;Re: [Fis] Szilard's Engine and Information&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Dr. Shu-Kun Lin &lt;<a href="mailto:lin&#64;mdpi.org?Subject=Re:%20[Fis]%20Szilard's%20Engine%20and%20Information">lin@mdpi.org</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue 06 Apr 2004 - 16:12:36 CEST</span><br />
</address>
<p>
Dear Michael,
<br />
<p>Thank you very much for your thoughtful paper which I read from the
<br />
first line to the last line. I would like to bring
<br />
to your attention our very recent special issue published in ENTROPY
<br />
on the topic &quot;Quantum Limits to the Second Law of Thermodynamics&quot;
<br />
at <a href="../../www.mdpi.net/entropy/list04.htm">http://www.mdpi.net/entropy/list04.htm</a>.
<br />
<p>You are invited to contribute this paper, after revision, on this 
<br />
related topic to
<br />
ENTROPY for consideration and publication. Please send your manuscript
<br />
by e-mail to Michel (E-mail: entropy&#64;mdpi.org, 
<br />
petitjean&#64;itodys.jussieu.fr).
<br />
Other colleagues, if you have a long piece, please send to Michel
<br />
for possible publication. Michel is the Editor-in-Chief of ENTROPY.
<br />
You know Michel is the &quot;Chair&quot; of the on-going session we are attending 
<br />
at FIS
<br />
right now.
<br />
<p>Regarding the related entropy of mixing (Delta S), it is certain that
<br />
the entropy of mixing is an information theoretical entropy
<br />
because there is no heat involved. It should not be taken as a typical
<br />
thermodynamic entropy (Delta S). Mixing of two chiral molecules
<br />
gas R and gas L you mentioned cannot be a thermal process. Therefore,
<br />
it is not a thermodynamic process in an heat engine. Mixing of R
<br />
and L cannot be used to generate mechanical work. This is a fact.
<br />
When we discuss the engine and related possibility of energy 
<br />
conservation, this fact
<br />
must be kept in mind.
<br />
<p>If the mixing of gas R and gas L would create work (a kind of mechanical 
<br />
energy
<br />
calculated as distance times force), one should be able to also create 
<br />
mechanical work by
<br />
mixing red color and black color.
<br />
<p>(Pedro, I will also be silent until the next week).
<br />
<p>Best regards,
<br />
Shu-Kun
<br />
<p>Michael Devereux wrote:
<br />
<p><em class="quotelev1">&gt; Dear Colleagues,
</em><br />
<em class="quotelev1">&gt; I’ve attached a PDF version of this message for those whose browser 
</em><br />
<em class="quotelev1">&gt; doesn’t do a good job of reproducing text formatting.
</em><br />
<em class="quotelev1">&gt; I am becoming more and more aware of the interest and help provided by 
</em><br />
<em class="quotelev1">&gt; other academic disciplines toward my understanding of information and 
</em><br />
<em class="quotelev1">&gt; entropy, and I appreciate Michel’s introduction in that regard. May I 
</em><br />
<em class="quotelev1">&gt; suggest a powerful model from physics for understanding the 
</em><br />
<em class="quotelev1">&gt; information-entropy relationship, at least as we physicists often use 
</em><br />
<em class="quotelev1">&gt; those terms in thermodynamics and measurement? ( I was an experimental 
</em><br />
<em class="quotelev1">&gt; particle physicist once, at the Los Alamos meson factory, then, in 
</em><br />
<em class="quotelev1">&gt; Switzerland working for the ETH on elementary particle experiments. 
</em><br />
<em class="quotelev1">&gt; I’ve taught at various universities in the U.S., and am now 
</em><br />
<em class="quotelev1">&gt; semi-retired. But, I’ve retained an abiding interest in quantum 
</em><br />
<em class="quotelev1">&gt; measurement, which has led to analysis of the Szilard engine and to 
</em><br />
<em class="quotelev1">&gt; calculation of the entropy cost of information processing. I expect I 
</em><br />
<em class="quotelev1">&gt; may return to full time work in some field related to quantum 
</em><br />
<em class="quotelev1">&gt; measurement or quantum information, if such an opportunity arrives. 
</em><br />
<em class="quotelev1">&gt; So, my experience and perspective is largely as a practicing 
</em><br />
<em class="quotelev1">&gt; physicist.) I understand that this model won’t address many of those 
</em><br />
<em class="quotelev1">&gt; concepts enumerated by Michel.
</em><br />
<em class="quotelev1">&gt; By far, the most effective and powerful physics model I know for 
</em><br />
<em class="quotelev1">&gt; investigating the relationship between thermodynamic entropy and 
</em><br />
<em class="quotelev1">&gt; information is the Szilard engine (Szilard, Z. Physik, 53, 1929, p. 
</em><br />
<em class="quotelev1">&gt; 840; Devereux, Found. Phys. Lett. 16, 1, 2003, p. 41, also available 
</em><br />
<em class="quotelev1">&gt; on the web from the Entropy server). Szilard discovered a very simple 
</em><br />
<em class="quotelev1">&gt; model that serves both as a heat engine and an information engine. It 
</em><br />
<em class="quotelev1">&gt; bridges the gap between a macroscopic measuring apparatus and 
</em><br />
<em class="quotelev1">&gt; microscopic information bit. Can anyone suggest a better model from 
</em><br />
<em class="quotelev1">&gt; physics? I’ve found it extremely useful for understanding the cost, in 
</em><br />
<em class="quotelev1">&gt; terms of energy and entropy, of quantum measurement, as well as the 
</em><br />
<em class="quotelev1">&gt; thermodynamic entropy needed for information processing. Specifically, 
</em><br />
<em class="quotelev1">&gt; the “information” here is the location, from measurement, of a single 
</em><br />
<em class="quotelev1">&gt; gas molecule in one or another half of a macroscopic cylinder.
</em><br />
<em class="quotelev1">&gt; But, the fatal problem with use of the Szilard engine model had been 
</em><br />
<em class="quotelev1">&gt; mistaken analysis of the engine cycle. Szilard suggested that the 
</em><br />
<em class="quotelev1">&gt; apparatus for measuring location of the gas molecule within the engine 
</em><br />
<em class="quotelev1">&gt; cylinder must produce entropy at measurement, in order to protect the 
</em><br />
<em class="quotelev1">&gt; Second Law of Thermodynamics. For nearly seventy-five years now, 
</em><br />
<em class="quotelev1">&gt; scientists have elaborated, expanded, and formalized that idea. (Zurek 
</em><br />
<em class="quotelev1">&gt; in Frontiers of Nonequillibrium Statistical Physics, 1984, p. 151; 
</em><br />
<em class="quotelev1">&gt; Lubkin, Int. J. Theo. Phys. 26, 1987, pp. 523-535; Brillouin, J. App. 
</em><br />
<em class="quotelev1">&gt; Phys., 22, 3, 1951, p. 334; etc. )
</em><br />
<em class="quotelev1">&gt; But, Szilard’s suggestion is mistaken, and quite obviously so, with a 
</em><br />
<em class="quotelev1">&gt; little careful consideration. In his model, after measurement of the 
</em><br />
<em class="quotelev1">&gt; location, either R or L, of the molecule in one side or the other of 
</em><br />
<em class="quotelev1">&gt; each of N cylinders of this engine, the memory register of the 
</em><br />
<em class="quotelev1">&gt; measurement apparatus will indicate, for example, (R, L, R, R, L, 
</em><br />
<em class="quotelev1">&gt; R,.....). That information is now fixed; it does not change over time 
</em><br />
<em class="quotelev1">&gt; with fluctuations of the thermodynamic system, as the engine’s gas 
</em><br />
<em class="quotelev1">&gt; molecule continues to collide with the cylinder. So, the 
</em><br />
<em class="quotelev1">&gt; information-dependent entropy of the apparatus is zero. Analogous, for 
</em><br />
<em class="quotelev1">&gt; example, to an ideal gas with the position and momentum of each gas 
</em><br />
<em class="quotelev1">&gt; molecule fixed at specific values. That entropy is zero. (As 
</em><br />
<em class="quotelev1">&gt; physicists calculate such things.)
</em><br />
<em class="quotelev1">&gt; Thus, the apparatus entropy could not have increased with measurement, 
</em><br />
<em class="quotelev1">&gt; and the Second Law is not protected from Maxwell’s demon by an 
</em><br />
<em class="quotelev1">&gt; apparatus entropy increase. Two philosophers of science, Earman and 
</em><br />
<em class="quotelev1">&gt; Norton, (Stud. Hist. Phil. Mod. Phys., Vol. 30, No. 1, pp. 1-40, 1999) 
</em><br />
<em class="quotelev1">&gt; published a quite extensive review of attempts to defend the Second 
</em><br />
<em class="quotelev1">&gt; Law from Maxwell’s demon with information-generated entropy, and found 
</em><br />
<em class="quotelev1">&gt; no creditable affirmative arguments. (Zurek, in the article cited 
</em><br />
<em class="quotelev1">&gt; above, wrote that the measurement outcome is unknown to some external 
</em><br />
<em class="quotelev1">&gt; observer, and so, the apparatus entropy is seen to increase by that 
</em><br />
<em class="quotelev1">&gt; observer. But, the demon observer must know the measurement outcome 
</em><br />
<em class="quotelev1">&gt; for every cylinder, in order to run the engine, and so he finds zero 
</em><br />
<em class="quotelev1">&gt; apparatus entropy. As we all know, no scientific law, including the 
</em><br />
<em class="quotelev1">&gt; Second Law, is observer dependent. If the demon observes no increase 
</em><br />
<em class="quotelev1">&gt; in entropy, then all external observers must also find no increase. 
</em><br />
<em class="quotelev1">&gt; This was one of my arguments against Zurek’s analysis. Earman and 
</em><br />
<em class="quotelev1">&gt; Norton offered another. I think Zurek’s idea is similar to von 
</em><br />
<em class="quotelev1">&gt; Neumann’s notion that quantum measurements are only completed when 
</em><br />
<em class="quotelev1">&gt; they become conscious to a human observer.)
</em><br />
<em class="quotelev1">&gt; I calculated the entropy change of the Szilard measurement apparatus 
</em><br />
<em class="quotelev1">&gt; (cited above). That entropy actually DECREASES by Nk ln(2) at 
</em><br />
<em class="quotelev1">&gt; measurement, indicating an apparatus (thermodynamic) information 
</em><br />
<em class="quotelev1">&gt; increase. Recall, however, from Maxwell’s original idea, that the 
</em><br />
<em class="quotelev1">&gt; demon operating such an engine not only measures the properties of the 
</em><br />
<em class="quotelev1">&gt; gas molecules, he also must move the cylinder partition. The Second 
</em><br />
<em class="quotelev1">&gt; Law would not be violated if such partition activation produced 
</em><br />
<em class="quotelev1">&gt; sufficient entropy. I believe this effect may be general for the usual 
</em><br />
<em class="quotelev1">&gt; type of Maxwell demons: that it is partition movement (door closure, 
</em><br />
<em class="quotelev1">&gt; etc.) which generates the entropy prescribed by the Second Law, not 
</em><br />
<em class="quotelev1">&gt; the entropy which is associated with the information of measurement. 
</em><br />
<em class="quotelev1">&gt; In spite of the innumerable publications claiming otherwise.
</em><br />
<em class="quotelev1">&gt; I’m somewhere near the middle of the calculation of the entropy 
</em><br />
<em class="quotelev1">&gt; generated by partition movement in Szilard’s engine. I think I can 
</em><br />
<em class="quotelev1">&gt; make that calculation quite general, and it appears, then, that I can 
</em><br />
<em class="quotelev1">&gt; use that result to determine the fundamental entropy cost of 
</em><br />
<em class="quotelev1">&gt; information processing. I mean what I’ve understood Charles Bennett 
</em><br />
<em class="quotelev1">&gt; and Rolf Landauer to mean by such things: entropy in terms of, say, 
</em><br />
<em class="quotelev1">&gt; the Gibbs formulation, and information processing as the logical 
</em><br />
<em class="quotelev1">&gt; manipulation of an information bit (erasure, overwriting, etc.). (The 
</em><br />
<em class="quotelev1">&gt; renowned philosopher of science, Karl Popper, thought that the Szilard 
</em><br />
<em class="quotelev1">&gt; engine could be operated without measurement, and thus, with no 
</em><br />
<em class="quotelev1">&gt; information transfer. If so, the engine might teach nothing about the 
</em><br />
<em class="quotelev1">&gt; relationship of entropy to information. But, Zurek displayed the 
</em><br />
<em class="quotelev1">&gt; quantum mechanical calculation for closure of the partition. The 
</em><br />
<em class="quotelev1">&gt; engine gas is not confined to half the cylinder by partition closure 
</em><br />
<em class="quotelev1">&gt; alone, but rather by the quantum measurement which follows closure. 
</em><br />
<em class="quotelev1">&gt; So, there must be information transfer to run the engine.) And, recall 
</em><br />
<em class="quotelev1">&gt; that the Szilard engine has been used by Charles Bennett and others as 
</em><br />
<em class="quotelev1">&gt; the model for information stored in a memory register. And, removal of 
</em><br />
<em class="quotelev1">&gt; the engine partition, followed by the measurement which reduces the 
</em><br />
<em class="quotelev1">&gt; quantum wave function, erases the information originally stored in the 
</em><br />
<em class="quotelev1">&gt; (engine) register (R,L,R,R,L,R,L,....).
</em><br />
<em class="quotelev1">&gt; Calculation of the entropy produced by partition closure isn’t quite 
</em><br />
<em class="quotelev1">&gt; as simple as I once assumed, though the results now seem to give the 
</em><br />
<em class="quotelev1">&gt; value I had anticipated. I do think it’s clear, in general, that 
</em><br />
<em class="quotelev1">&gt; prompt movement of a physical object, like the engine partition, will 
</em><br />
<em class="quotelev1">&gt; produce thermodynamic entropy. Consider the movement of the cylinder 
</em><br />
<em class="quotelev1">&gt; in a heat engine, for example. (No quasi-static processes allowed.)
</em><br />
<em class="quotelev1">&gt; The calculation, so far, is incomplete, but it has shown something I 
</em><br />
<em class="quotelev1">&gt; find really remarkable. The specific information needed to run the 
</em><br />
<em class="quotelev1">&gt; Szilard heat engine is carried by a time signal, not by change in a 
</em><br />
<em class="quotelev1">&gt; macroscopic physical configuration of any type. It’s this time signal 
</em><br />
<em class="quotelev1">&gt; which causes the decrease in apparatus entropy, since it specifies the 
</em><br />
<em class="quotelev1">&gt; captured molecule’s position. No heat is transferred to or from the 
</em><br />
<em class="quotelev1">&gt; apparatus at measurement, so it shows no change in Clausius’ entropy, 
</em><br />
<em class="quotelev1">&gt; Delta Q / T. I’m unaware of any definition of entropy which explicitly 
</em><br />
<em class="quotelev1">&gt; includes a time dependence. Does anyone else know of such?
</em><br />
<em class="quotelev1">&gt; I think there is, however, a change in entropy, (and, of thermodynamic 
</em><br />
<em class="quotelev1">&gt; information) as determined by the Shannon-von Neumann probability 
</em><br />
<em class="quotelev1">&gt; formulation. I suspect that, in determining the probabilities we 
</em><br />
<em class="quotelev1">&gt; assign to thermodynamic configurations, we must include those that are 
</em><br />
<em class="quotelev1">&gt; time-dependent. And, I’ve found that the entropy cost of partition 
</em><br />
<em class="quotelev1">&gt; movement also depends on the time employed for that movement.
</em><br />
<em class="quotelev1">&gt; Thank you, Michel, for the introduction and direction for this 
</em><br />
<em class="quotelev1">&gt; discussion.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Cordially,
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Michael Devereux
</em><br />
<em class="quotelev1">&gt;
</em><br />
<p><p>_______________________________________________
<br />
fis mailing list
<br />
fis&#64;listas.unizar.es
<br />
<a href="../../webmail.unizar.es/mailman/listinfo/fis">http://webmail.unizar.es/mailman/listinfo/fis</a>
<br />
<span id="received"><dfn>Received on</dfn> Tue Apr  6 16:13:27 2004</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1403.html" title="Next message in the list">jakulin@acm.org: "RE: [Fis] Szilard's Engine and Information"</a></li>
<li><dfn>Previous message</dfn>: <a href="1401.html" title="Previous message in the list">Pedro C. Marijuán: "Re: [Fis] FIS / introductory text / 5 April 2004"</a></li>
<li><dfn>In reply to</dfn>: <a href="1400.html" title="Message to which this message replies">Michael Devereux: "[Fis] Szilard's Engine and Information"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1419.html" title="Next message in this discussion thread">Stanley N. Salthe: "Re: [Fis] Szilard's Engine and Information"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1419.html" title="Message sent in reply to this message">Stanley N. Salthe: "Re: [Fis] Szilard's Engine and Information"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#1402" title="Contemporary messages by date">By Date</a> ] [ <a href="index.html#1402" title="Contemporary discussion threads">By Thread</a> ] [ <a href="subject.html#1402" title="Contemporary messages by subject">By Subject</a> ] [ <a href="author.html#1402" title="Contemporary messages by author">By Author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">By messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="../../www.hypermail.org/default.htm">hypermail 2.1.8</a> 
: Mon 07 Mar 2005 - 10:24:46 CET
</em></small></p>
</body>
</html>
